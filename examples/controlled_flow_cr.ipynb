{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervisor - Worker Controlled Flow for Gen Pod AI Backend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules Needed for this Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JsonOutputParser\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_core'"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "from langchain_core.messages.tool import ToolCall\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "\n",
    "from langgraph.graph import END\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# from langchain_core.agents import AgentAction\n",
    "# from langchain_core.agents import AgentFinish\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from typing import List\n",
    "from typing import Dict\n",
    "from typing import Union\n",
    "from typing import Literal\n",
    "from typing import ClassVar\n",
    "from typing import Sequence\n",
    "from typing import TypedDict\n",
    "from typing import Annotated\n",
    "\n",
    "from pydantic import Field\n",
    "from pydantic import BaseModel\n",
    "from pydantic import ValidationError\n",
    "\n",
    "from typing_extensions import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import pprint as pp\n",
    "\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "import requests\n",
    "import operator\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us import some basic libraries and load dotenv file, make sure it contains necessary API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants for the project       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node names used in graph\n",
    "class GraphNodes(Enum):\n",
    "    ARCHITECT: str = \"ARCHITECT\"\n",
    "\n",
    "    CODER: str = \"CODER\"\n",
    "\n",
    "    EXECUTE_COMMAND: str = \"EXECUTE_COMMAND\"\n",
    "    CREATE_GIT_REPO: str = \"CREATE_GIT_REPO\"\n",
    "    VERIFY_FILE_CONTENT: str = \"VERIFY_FILE_CONTENT\"\n",
    "    CHECK_FILES_CREATED: str = \"CHECK_FILES_CREATED\"\n",
    "    DOWNLOAD_LICENSE_FILE: str = \"DOWNLOAD_LICENSE_FILE\"\n",
    "    WRITE_GENERATED_CODE_TO_FILE: str = \"WRITE_GENERATED_CODE_TO_FILE\"\n",
    "\n",
    "    START: str = \"__START__\"\n",
    "    END: str = END\n",
    "\n",
    "    CALL_TOOL: str = \"CALL_TOOL\"                     \n",
    "    \n",
    "    NONE: str = \"\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value\n",
    "\n",
    "# Task states decided by llm\n",
    "class TaskState(Enum):\n",
    "    NEW: str = \"NEW\"\n",
    "    AWAITING: str = \"AWAITING\"\n",
    "    HALT: str = \"HALT\"\n",
    "    PENDING: str = \"PENDING\"\n",
    "    COMPLETED: str = \"COMPLETED\"\n",
    "    INCOMPLETE: str = \"INCOMPLETE\"\n",
    "    DONE: str = \"DONE\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value\n",
    "\n",
    "# roles that gonna be used while adding messages to graph state\n",
    "class ChatRoles(Enum):\n",
    "    AI: str = \"assistant\"\n",
    "    TOOL: str = \"tool\"\n",
    "    USER: str = \"user\"\n",
    "    SYSTEM: str = \"system\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value\n",
    "\n",
    "# whitelisted commands for the llm that can be used to complete the task\n",
    "ALLOWED_COMMANDS = ['mkdir', 'docker', 'python', 'python3', 'pip', 'virtualenv', 'mv', 'pytest', 'touch', 'cat', 'ls', 'curl'] #uvicorn\n",
    "\n",
    "# Update this path to your local directory where you want to create the project at.\n",
    "PROJECT_PATH = os.getenv('PROJECT_PATH','/This/Is/The/Path/To/Create/Your/Project/')\n",
    "print(\"PROJECT_PATH: \", PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enums value behaviour\n",
    "\n",
    "we need its value so we use second method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatRoles.AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatRoles.AI.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables and instances      for the projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading LLM\n",
    "# We will load OpenAI GPT-4o LLM to assist our agents.\n",
    "llm = ChatOpenAI(model=\"gpt-4o-2024-05-13\", temperature=0, max_retries=5, streaming=True, seed=4000)\n",
    "code_llm = ChatOpenAI(model=\"gpt-4-turbo-2024-04-09\",temperature=0.3, max_retries=5, streaming=True, seed=4000)\n",
    "\n",
    "# tools that coder agent can access\n",
    "coder_tools = [\"write_generated_code_to_file\", \"create_git_repo\", \"execute_command\", \"download_license_file\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us create some Utility function\n",
    "These function can help later on to read the input files as a json string and create agents that can be later used as nodes in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input_json(file_path) -> str:\n",
    "    \"\"\"Reads JSON data from a file and returns it as a string.\n",
    "\n",
    "    Args:\n",
    "        file_path: The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        A string representation of the JSON data.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as user_input_file:\n",
    "        data = json.load(user_input_file)\n",
    "    \n",
    "    user_input = json.dumps(data)\n",
    "    license_txt = data[\"LICENSE_TEXT\"]\n",
    "\n",
    "    return user_input, license_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tools to be used by Agents\n",
    "These tools are custom fuctions that will also go as nodes in the graph and will be called by the agent to take some action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def download_license_file(\n",
    "        url: Annotated[str, \"LICENSE_URL from where it has to be downloaded.\"],\n",
    "        file_path: Annotated[str, \"Absolute path where the License.md should be written can handle directory create if does not exist.\"]\n",
    " ) -> str:\n",
    "    \"\"\"\n",
    "    Downloads a license file from a given URL and saves it locally.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL of the lic\n",
    "    ense file.\n",
    "    file_path (str): Absolute path where the generated code should be written can handle directory create if does not exist.\n",
    "    \n",
    "    Returns:\n",
    "    str: The local path where the file was saved.\n",
    "    \"\"\"\n",
    "    import pprint as pp\n",
    "    response = requests.get(url)\n",
    "    # print(response.content)\n",
    "    # response.raise_for_status()  # Raise exception if the request failed\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        return f\"Successfully wrote the License to {file_path}\"\n",
    "\n",
    "    except:\n",
    "        return f\"failed to write the License to {file_path}\"\n",
    "\n",
    "@tool\n",
    "def write_generated_code_to_file(\n",
    "    generated_code: Annotated[str, \"The code generated by the agent.\"],\n",
    "    file_path: Annotated[str, \"Absolute path where the generated code should be written can handle directory create if does not exist.\"]\n",
    "):\n",
    "    \"\"\"\n",
    "    Writes the provided generated code to the specified file within the project structure.\n",
    "\n",
    "    Args:\n",
    "        generated_code (str): The code generated by the agent.\n",
    "        file_path (str): The path where the generated code should be written.\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        # Ensure the directory exists before writing the file\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        \n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(generated_code)\n",
    "        \n",
    "        return {'project_files':file_path}, f\"Successfully wrote the generated code to: {file_path}\"\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to write generated code. Error: {repr(e)}\"\n",
    "    \n",
    "@tool\n",
    "def create_git_repo(\n",
    "    project_name: Annotated[str, \"Name of the new Git repository that should be created.\"],\n",
    "    repo_path: Annotated[str,\"Path where the repository is created.\"]\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a new Git repository at the specified path.\n",
    "\n",
    "    Args:\n",
    "        project_name (str): Name of the new Git repository that should be created.\n",
    "        PROJECT_PATH (str): Path where the new Git repository will be created.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the path of the newly created Git repository or an error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        repo_path = os.path.join(PROJECT_PATH, project_name)\n",
    "        \n",
    "        # Ensure the directory exists before initializing the Git repository\n",
    "        os.makedirs(repo_path, exist_ok=True)\n",
    "        \n",
    "        subprocess.check_output(['git', 'init'], cwd=repo_path)\n",
    "        \n",
    "        return {'repo_path': repo_path}, f\"Git repository created successfully: {repo_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Failed to create a new Git repository. Error: {repr(e)}\"\n",
    "\n",
    "@tool\n",
    "def execute_command(\n",
    "    command: Annotated[str, \"The complete set of commands to be executed on the local machine in order.\"],\n",
    "    repo_path: Annotated[str,\"Path where the repository is created.\"]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Executes a command on the local machine. This function is only allowed to use the following commands:\n",
    "\n",
    "    'mkdir', 'docker', 'python', 'python3', 'pip', 'virtualenv', 'mv', 'pytest',\n",
    "    'touch', 'cat', 'ls', 'curl'\n",
    "\n",
    "    Args:\n",
    "        command (str): The complete set of commands to be executed on the local machine in order.\n",
    "        repo_path(str): absolute path where the command has to run.\n",
    "    \"\"\"\n",
    "    # Split the command into parts\n",
    "    parts = command.split()\n",
    "    \n",
    "    # Check if the command is in the whitelist\n",
    "    if parts[0] not in ALLOWED_COMMANDS:\n",
    "        return f\"Command '{parts[0]}' is not allowed.\"\n",
    "    \n",
    "    try:\n",
    "        # Execute the command\n",
    "        # full_path = os.path.join(PROJECT_PATH,repo_path)\n",
    "        additional_command = f\"cd {repo_path} && \"\n",
    "        updated_command = additional_command + command\n",
    "        result = subprocess.check_output(updated_command, shell=True)\n",
    "        \n",
    "        return f\"Command executed successfully. Output: {result}\"\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute command. Error: {repr(e)}\"\n",
    "    \n",
    "@tool\n",
    "def check_files_created(\n",
    "    files: Annotated[List[str], \"The list of files that should be present in the project repository.\"],\n",
    "    repo_path: Annotated[str, \"Absolute Path where the repository is created.\"]\n",
    "):\n",
    "    \"\"\"\n",
    "    Checks if all the specified files within a folder structure are created or not.\n",
    "\n",
    "    Args:\n",
    "        files (List[str]): The list of files to check.\n",
    "    \"\"\"\n",
    "    missing_files = []\n",
    "    \n",
    "    # Check each file\n",
    "    for file in files:\n",
    "        full_file_path = os.path.join(repo_path, file)\n",
    "        \n",
    "        # Directly check if the file exists without executing shell commands\n",
    "        if not os.path.exists(full_file_path):\n",
    "            missing_files.append(file)\n",
    "    \n",
    "    if missing_files:\n",
    "        return {\"missing_files\":missing_files}, f\"missing these files: {missing_files}\"\n",
    "    else:\n",
    "        return \"All files are present.\"\n",
    "    \n",
    "@tool\n",
    "def verify_file_content(\n",
    "    files: Annotated[List[str], \"The list of files that should be present in the project repository.\"],\n",
    "    repo_path: Annotated[str, \"Absolute Path where the repository is created.\"]\n",
    "):\n",
    "    \"\"\"\n",
    "    Checks if all the specified files within a folder structure are empty or not.\n",
    "\n",
    "    Args:\n",
    "        files (List[str]): The list of files to check.\n",
    "    \"\"\"\n",
    "    \n",
    "    empty_files = []\n",
    "    \n",
    "    # Check each file\n",
    "    for file in files:\n",
    "        \n",
    "        full_file_path = os.path.join(repo_path, file)\n",
    "        \n",
    "        # Check if the file exists and is empty\n",
    "        if os.path.exists(full_file_path) and os.path.getsize(full_file_path) == 0:\n",
    "            empty_files.append(file)\n",
    "    \n",
    "    if empty_files:\n",
    "        return f\"These files are empty: {empty_files}\"\n",
    "    else:\n",
    "        return \"All files are not empty.\"\n",
    "\n",
    "\n",
    "coder_tools_list = [write_generated_code_to_file, create_git_repo, execute_command, download_license_file]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Define a New State that will maintain all the statespace needed to run the architect coder flow smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    \n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        messages : With user question, error messages, reasoning\n",
    "        generation : Code solution\n",
    "        iterations : Number of tries\n",
    "    \"\"\"\n",
    "\n",
    "    error: Annotated[bool, \"tells if previous step has encountered an error.\"] = Field(default=False)\n",
    "    generation: Annotated[str, Field(default=\"\")] # TODO: Need to proper description for field\n",
    "    iterations: Annotated[int, Field(default=0, description=\"number of steps the current flow has took till now\")]\n",
    "    messages: Annotated[list, Field(default=[], description=\"all messages that were generated during the flow\")]\n",
    "    # when ever coder need to use tools. it assigns one tool call from pending tool calls to here.\n",
    "    curr_tool_call: Annotated[dict, Field(default={}, description=\"holds the details required for the current tool call.\")]\n",
    "    curr_task_status: Annotated[str, Field(default=TaskState.NEW.value, description=\"status of the current task assigned to coder.\")]\n",
    "    current_step: Annotated[str, Field(default=\"\", description=\"current step coder tyring to finish\")]\n",
    "\n",
    "    # Architect controlled/updated fields\n",
    "    project_name: Annotated[str, Field(default=\"\", description=\"Project name that the user has assigned to work on\")]\n",
    "    requirements_overview: Annotated[str, Field(default=\"\", description=\"A comprehensive summary of the project’s requirements, outlining the necessary functionalities and features.\")]\n",
    "    tasks: Annotated[list[str], Field(default=[], description=\"list of tasks with detailed requirements into independent task with as much context as possible that are crucial to follow during completion\")]\n",
    "    project_folder_structure: Annotated[str, Field(default=\"\", description=\"Project folder structure to follow.\")]\n",
    "    current_task: Annotated[str, Field(default=\"\", description=\"Task to do with all the functional and non functional details related to that task\")]\n",
    "    \n",
    "    # Coder controlled/updated fields\n",
    "    file_path: Annotated[str, Field(description=\"Depending on the project structure where should the code be written to\"), operator.add]\n",
    "    code: Annotated[str, Field(description=\"Fully complete, well documented code, with all the naming standards followed that is needed to complete the task.\"), operator.add]\n",
    "    # needs to be updated after coder llm is called.\n",
    "    coder_steps: Annotated[list, Field(default=[], description=\"Steps needed to complete coder task.\")]\n",
    "    coder_response: Annotated[str, Field(default=\"\", description=\"Parsed Coder response after architect assigning the task to coder\")]\n",
    "    # if there are calls to different tools at the same time then they are stored here to schedule their execution.\n",
    "    pending_tool_calls: Annotated[list, Field(default=[], description=\"list of tool calls requested by coder to complete tasks\")]\n",
    "    license_text: Annotated[str, Field(default=\"\", description=\"A Licensing text from the user input that needs to be prefixed to each code.\")]\n",
    "    files_to_create: Annotated[str, \"files need to be written to local.\"]\n",
    "    # controlled/updated fields all nodes\n",
    "    project_status: Annotated[str, Field(default=TaskState.NEW.value, description=\"current status of the project.\", )]\n",
    "    call_next: Annotated[str, Field(default=GraphNodes.NONE.value, description=\"Whom to call next\")]\n",
    "    max_retry: int\n",
    "\n",
    "def add_message(state, message: tuple[str, str]) -> GraphState:\n",
    "    \"\"\"\n",
    "    Adds a single message to the the messages\n",
    "\n",
    "    message: tuple[str, str]\n",
    "\n",
    "    Ex: add_message(state, ('user', 'single message'))\n",
    "    \"\"\"\n",
    "\n",
    "    state['messages'] += [message]\n",
    "    return state\n",
    "\n",
    "def add_messages(state, messages: list[tuple[str, str]]) -> GraphState:\n",
    "    \"\"\"\n",
    "    Adds a list of messages to the messages\n",
    "\n",
    "    messages: list[tuple[str, str]]\n",
    "\n",
    "    Ex: add_messages(state, [('user', 'message 1'), ('ai', 'message 2)])\n",
    "    \"\"\"\n",
    "    state['messages'] += messages\n",
    "\n",
    "    return state\n",
    "\n",
    "def get_messages_for_prompt(state) -> list[tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Returns last 5 messages from messages field.\n",
    "\n",
    "    Ex: messages = get_messages_for_prompt(state)\n",
    "    \"\"\"\n",
    "\n",
    "    return state['messages']\n",
    "\n",
    "def get_last_message(state) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Fetches the last message from messages field.\n",
    "    \n",
    "    Ex: last_message = get_last_message(state)\n",
    "    \"\"\"\n",
    "\n",
    "    return state['messages'][-1]\n",
    "\n",
    "def toggle_error(state) -> GraphState:\n",
    "    \"\"\"\n",
    "    toggle error field. true -> false and flase -> true\n",
    "\n",
    "    Ex: state.toggle_error()\n",
    "    \"\"\"\n",
    "\n",
    "    state['error'] = not state['error']\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def next_major_task(state) -> str:\n",
    "    \"\"\"\n",
    "    returns \n",
    "        None when list is empty.\n",
    "        The next available task when non empty.\n",
    "\n",
    "    Ex: next_task = next_major_task(state)\n",
    "    \"\"\"\n",
    "\n",
    "    if len(state['tasks']) == 0:\n",
    "        return None\n",
    "    \n",
    "    return state['tasks'].pop(0)\n",
    "\n",
    "def next_coder_step(state) -> str:\n",
    "    \"\"\"\n",
    "    returns \n",
    "        None when list is empty.\n",
    "        The next available step when non empty.\n",
    "\n",
    "    Ex: next_step = state.next_coder_step()\n",
    "    \"\"\"\n",
    "\n",
    "    if len(state['coder_steps']) == 0:\n",
    "        return None\n",
    "    \n",
    "    return state['coder_steps'].pop(0)\n",
    "\n",
    "def next_pending_tool_call(state) -> dict:\n",
    "    \"\"\"\n",
    "    returns \n",
    "        None when list is empty.\n",
    "        The next available tool call on pending_tool_call field.\n",
    "\n",
    "    Ex: tool_call = state.next_pending_tool_call()        \n",
    "    \"\"\"\n",
    "\n",
    "    if len(state['pending_tool_calls']) == 0:\n",
    "        return None\n",
    "    \n",
    "    return state['pending_tool_calls'].pop(0)\n",
    "\n",
    "def get_project_state(state) -> str:\n",
    "    \"\"\"\n",
    "    returns current task status.\n",
    "\n",
    "    Ex: task_status = state.get_project_state()\n",
    "    \"\"\"\n",
    "\n",
    "    return state['project_status']\n",
    "\n",
    "def get_next(state) -> str:\n",
    "    \"\"\"\n",
    "    returns next node to be called.\n",
    "    \n",
    "    Ex: next = state.get_next()\n",
    "    \"\"\"\n",
    "\n",
    "    return state['call_next']\n",
    "\n",
    "def set_curr_tool_call_from_pending_tool_calls(state) -> GraphState:\n",
    "    \"\"\"\n",
    "    updates the curr_tool_call from the pending tool calls.\n",
    "\n",
    "    Ex: state.set_curr_tool_call_from_pending_tool_calls()\n",
    "    \"\"\"\n",
    "\n",
    "    tool_call = next_pending_tool_call(state)\n",
    "    if tool_call is None:\n",
    "        state['curr_tool_call'] = {}\n",
    "    else:\n",
    "        state['curr_tool_call'] = tool_call\n",
    "\n",
    "    return state\n",
    "\n",
    "def get_curr_tool_call(state) -> dict:\n",
    "    \"\"\"\n",
    "    returns the current tool call which need to be processed.\n",
    "\n",
    "    Ex: tool_call = get_curr_tool_call(state)\n",
    "    \"\"\"\n",
    "\n",
    "    return state['curr_tool_call']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's us define a Data model that we can use to update the call's in the graph plus also to define a schema of response from the llm's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic class used by architect chain for structuring output\n",
    "class RequirementsDoc(BaseModel):\n",
    "    \"\"\"Requirements Document output\"\"\"\n",
    "\n",
    "    project_name: str = Field(description=\"Project name that the user has assigned you to work on\", required=True)\n",
    "    well_documented: str = Field(description=\"Well built requirements document from the user input\", required=True)\n",
    "    tasks: str = Field(description=\"Spilt the detailed requirements into list of tasks with as much context as possible that are crucial to follow during completion\", required=True)\n",
    "    project_folder_structure: str = Field(description=\"Project folder structure to follow.\", required=True)\n",
    "    next_task: str = Field(description=\"Next Task to do with all the functional and non functional details related to that task\", required=True)\n",
    "    call_next: str = Field(description=\"name of the node that the flow has to follow next\", required=True)\n",
    "    project_status: str = Field(description=\"status of the project. whether all the tasks needed for project completion are completed or not\", required=True)\n",
    "\n",
    "\n",
    "    # deliverables: Dict[str, str] = Field(default_factory=dict, description=\"A seperate Dictionary of Tasks and their corresponding details for completion\", required=True)\n",
    "    description: ClassVar[str] = \"Schema of what all documents should be generated.\"\n",
    "\n",
    "# Pydantic class used by coder chain for structuring output\n",
    "class CoderModel(BaseModel):\n",
    "    \"\"\"Coder agent output\"\"\"\n",
    "\n",
    "    steps_to_complete: str = Field(description=\"If the task cannot be completed in one step and needs external tool\", required=True)\n",
    "    files_to_create: str = Field(description=\"What all files needs to be created\", required=True)\n",
    "    file_path: str = Field(description=\"Depending on the project structure where should the code be written to\", required=True)\n",
    "    code: str = Field(description=\"Fully complete, well documented code, with all the naming standards followed that is needed to complete the task.\", required=True)\n",
    "    license_text: str = Field(description=\"A Licensing text from the user input that needs to be prefixed to each code.\", required=True)\n",
    "    project_status: str = Field(description=\"status of the project. whether all the tasks needed for project completion are completed or not\", required=True)\n",
    "    call_next: str = Field(description=\"name of the node that the flow has to follow next\", required=True)\n",
    "\n",
    "    # deliverables: Dict[str, str] = Field(default_factory=dict, description=\"A seperate Dictionary of Tasks and their corresponding details for completion\")\n",
    "    description: ClassVar[str] = \"Schema of task completion output from Coder.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic classes for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolChainValidator(BaseModel):\n",
    "    content: Union[str, List[Union[str, Dict]]]\n",
    "    tool_calls: list[ToolCall] = Field(min_length=1)\n",
    "    additional_kwargs: dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ToolChainValidator(content=[\"hjkl\"], tool_calls=[], additional_kwargs={})\n",
    "except ValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architect_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            ChatRoles.SYSTEM.value,\n",
    "    \n",
    "            \"\"\"<instructions> You are a Development Lead in charge of implementing the given project. Thoroughly analyze the user input and build a thorough requirements document needed to implement the project. \n",
    "            You should also be able to break them into independent tasks that can be assigned to other team memeber.\\\n",
    "            Enforce the use of microservice architecture, Best practices Project Folder structure, 12-factor application standards,\\\n",
    "            domain-driven microservice application design, clean-code development architecture standards in the requirements document\\\n",
    "            Final project should include all the source files, configuration files, unit test files, OpenAPI specfile for the project in YAML, License.md file from the User provided URL, a Requirements.txt file, Dockerfile, gitignore and a dockerignore file.\n",
    "            Structure your answer: \n",
    "            1) pick the project name from the user input, \n",
    "            2) A well defined complete requirements document, \n",
    "            3) Breaking down the tasks into a separate List of tasks that are required to be completed in the project with all the functional and nonfunctional requirements is quintessential and is needed to perform the task smoothly, a list of string should look like ['task1','task2,...,'taskn'].\n",
    "            4) Project_folder_structure to be enforced for the project \n",
    "            5) What should be the next task if we decide to start working on the project. Pick it up sequentially from the available tasks and add any necessary information for the team member to complete the task.\\n \n",
    "            6) Sequentially assign each task from the tasks field to the next_task field. After each assignment, set the project status to `{pending}`. Once a team member completes a task, confirm its completion before proceeding to the next task. Continue this process until all tasks are completed. Only when all tasks are finished and confirmed by the team members, should the project status be updated to `{completed}`.\n",
    "            7) Add this to the list of tasks 'write an well defined requirements documentation file in a markdown format to local file system as a 'requirements.md' file in 'docs' folder'.\n",
    "            Invoke the RequirementsDoc tool to structure the output correctly. </instructions> \\n Here is the user question:\"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "architect_prompt = architect_prompt.partial(pending=TaskState.PENDING.value)\n",
    "architect_prompt = architect_prompt.partial(completed=TaskState.COMPLETED.value)\n",
    "\n",
    "\n",
    "coder_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            ChatRoles.SYSTEM.value,\n",
    "    \n",
    "            \"\"\"<instructions>\n",
    "            You are an expert programmer collaborating with the Architect in your team to complete an end to end Coding Project.\n",
    "            You are good at writing well documented, optimized, secure and productionizable code.\n",
    "            Here are the standards that you need to follow explicitly for this project:\n",
    "            1. You do not assume anything and asks Architect for additional context and clarification if requirements are not clear.\n",
    "            2. Must follow Project Folder Structure decided by Architect.\n",
    "            3. Must Write the files to the local filesystem.\n",
    "            4. Follow microservices development standards like 12-factor application standards, domain-driven microservice architecture and clean-code development architecture standards.\n",
    "\n",
    "            Structure your answer: \n",
    "            1) Multiple steps may be needed to complete this task that needs access to some external tools `{coder_tools}`, if so add these steps and mark the project_status as InComplete and call_next to call_tool.\n",
    "            2) Depending on the project structure where should the code be written to, \n",
    "            3) Fully complete, well documented code, with all the naming standards to follow, that is needed to complete the task., \n",
    "            4) A Licensing text from the user input that needs to be prefixed to each code. \n",
    "            5) Mark the assigned task as '{completed}' and set the call_next to '{architect}', only after receiving the confirmation from one of the external tools. \n",
    "            6) Mark the assigned task as '{incomplete}' and set the call_next to '{call_tool}'\\n\n",
    "            Invoke the CoderModel tool to structure the output correctly. </instructions> \\n Here is the Architect task:\"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"coder_tools\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "coder_prompt = coder_prompt.partial(completed=TaskState.COMPLETED.value)\n",
    "coder_prompt = coder_prompt.partial(incomplete=TaskState.INCOMPLETE.value)\n",
    "coder_prompt = coder_prompt.partial(architect=GraphNodes.ARCHITECT.value)\n",
    "coder_prompt = coder_prompt.partial(call_tool=GraphNodes.CALL_TOOL.value)\n",
    "\n",
    "tool_prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architect_chain = architect_prompt | llm.with_structured_output(RequirementsDoc, include_raw=True)\n",
    "\n",
    "coder_chain = coder_prompt | code_llm.with_structured_output(CoderModel, include_raw=True)\n",
    "\n",
    "tool_chain = tool_prompt | llm.bind_tools(coder_tools_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coder_tools_executor = ToolExecutor(coder_tools_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Nodes and their routers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def architect_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    architect node\n",
    "    \"\"\"\n",
    "    expected_keys = []\n",
    "    architect_solution = {}\n",
    "\n",
    "    # reset the error \n",
    "    if state['error']:\n",
    "       state = toggle_error(state)\n",
    "    \n",
    "    if state['project_status'] == TaskState.NEW.value:\n",
    "        architect_solution = architect_chain.invoke({'messages': get_messages_for_prompt(state)})\n",
    "        expected_keys = [item for item in RequirementsDoc.__annotations__ if item != \"description\"]\n",
    "    elif state['curr_task_status'] == TaskState.AWAITING.value:\n",
    "        state = add_message(state, (\n",
    "            ChatRoles.USER.value,\n",
    "            \"Looks like team member has completed the previously assigned task. Please assign new task if any.\"\n",
    "        ))\n",
    "        # temp_state = state.copy()\n",
    "        # # Deleting 'messages' from 'temp_state' to optimize prompt token size. \n",
    "        # del temp_state['messages']\n",
    "\n",
    "        # architect_solution = architect_chain.invoke({'context': f'{temp_state}', 'messages': get_messages_for_prompt(state)})\n",
    "        # expected_keys = ['next_task']\n",
    "    \n",
    "    # Check if any fields in the schema are missing values.\n",
    "    missing_keys = [] \n",
    "    for key in expected_keys:\n",
    "        if key not in architect_solution['parsed']:\n",
    "            missing_keys.append(key)\n",
    "\n",
    "    if ('parsing_error' in architect_solution) and architect_solution['parsing_error']:\n",
    "        raw_output = architect_solution['raw']\n",
    "        error = architect_solution['parsing_error']\n",
    "\n",
    "        state = toggle_error(state)\n",
    "        state = add_message(state, (\n",
    "            ChatRoles.USER.value,\n",
    "            f\"ERROR: parsing your output! Be sure to invoke the tool. Output: {raw_output}. \\n Parse error: {error}\"\n",
    "        ))\n",
    "    elif missing_keys:\n",
    "        state = toggle_error(state)\n",
    "        state = add_message(state, (\n",
    "            ChatRoles.USER.value,\n",
    "            f\"ERROR: Now, try again. Invoke the RequirementsDoc tool to structure the output with a project_name, well_documented, tasks, project_folder_structure, next_task and call_next, you missed {missing_keys} in your previous response\",        \n",
    "        ))\n",
    "    elif state['curr_task_status'] == TaskState.AWAITING.value:\n",
    "        state['current_task'] = next_major_task(state)\n",
    "        state['curr_task_status'] = TaskState.NEW.value\n",
    "\n",
    "        # print(\"Architect Task Completion\")\n",
    "        # pp.pp(architect_solution)\n",
    "        \n",
    "        if state['current_task'] is None:\n",
    "            state['project_status'] = TaskState.COMPLETED.value\n",
    "        else:\n",
    "            state['project_status'] = TaskState.INCOMPLETE.value\n",
    "            \n",
    "        state = add_message(state, (\n",
    "            ChatRoles.AI.value,\n",
    "            f\"A new task: '{state['current_task']}' has been assigned! Please check the details and start working on it.\"\n",
    "        ))\n",
    "        # TODO->DONE: Use this case for updating the next_step.\n",
    "        # invoke architect node in such a way that it only updates the next step.\n",
    "        # maybe adding a new field to state or special value to the task_state \n",
    "        # might be helpful for this situation.\n",
    "        # add message as well stating a new task has been assigned for the coder.\n",
    "        pass\n",
    "    else:\n",
    "        state['requirements_overview'] = architect_solution['parsed']['well_documented']\n",
    "        state['project_name'] = architect_solution['parsed']['project_name']\n",
    "        state['project_folder_structure'] = architect_solution['parsed']['project_folder_structure']\n",
    "        state['tasks'] = ast.literal_eval(architect_solution['parsed']['tasks'])\n",
    "        state['current_task'] = next_major_task(state)\n",
    "        state['curr_task_status'] = TaskState.NEW.value\n",
    "\n",
    "        state = add_message(state, (\n",
    "            ChatRoles.AI.value,\n",
    "            \"Well document requirements is present now. see what task needs to be completed and do that now.\",\n",
    "        ))\n",
    "\n",
    "    return state\n",
    "\n",
    "def architect_router(state: GraphState) -> str:\n",
    "    \"\"\"\n",
    "    architect router\n",
    "    \"\"\"\n",
    "                       #happens when new task need to be assigned\n",
    "    if state['error'] or (state['curr_task_status'] == TaskState.AWAITING.value):\n",
    "        return GraphNodes.ARCHITECT.value\n",
    "    \n",
    "    if state['project_status'] == TaskState.COMPLETED.value:\n",
    "        return GraphNodes.END.value\n",
    "\n",
    "    # if current_task_status is not TaskState.DONE.value then coder\n",
    "    return GraphNodes.CODER.value\n",
    "\n",
    "def coder_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    coder node\n",
    "    \"\"\"\n",
    "    expected_keys = []\n",
    "\n",
    "    # reset error\n",
    "    if state['error']:\n",
    "        state = toggle_error(state)\n",
    "\n",
    "        \n",
    "    question = f\"Here is a task for you to complete {state['current_task']}.\"\n",
    "    context = state['project_folder_structure']\n",
    "\n",
    "    if state['curr_task_status'] == TaskState.NEW.value:\n",
    "        coder_solution = coder_chain.invoke({\"context\": context, \"coder_tools\": coder_tools, \"messages\": [(ChatRoles.USER.value, question)]})\n",
    "        expected_keys = [item for item in CoderModel.__annotations__ if item != \"description\"]\n",
    "\n",
    "        if state['project_status'] == TaskState.NEW.value:\n",
    "            state['project_status'] = TaskState.PENDING.value\n",
    "\n",
    "        missing_keys = []\n",
    "        for key in expected_keys:\n",
    "            if key not in coder_solution['parsed']:\n",
    "                missing_keys.append(key)\n",
    "        \n",
    "        if coder_solution['parsing_error']:\n",
    "            raw_output = coder_solution['raw']\n",
    "            error = coder_solution['parsing_error']\n",
    "\n",
    "            state = toggle_error(state)\n",
    "            state = add_message(state, (\n",
    "                ChatRoles.USER.value,\n",
    "                f\"ERROR: parsing your output! Be sure to invoke the tool. Output: {raw_output}. \\n Parse error: {error}\"\n",
    "            ))\n",
    "        elif missing_keys:\n",
    "            state = toggle_error(state)\n",
    "            state = add_message(state, (\n",
    "                ChatRoles.USER.value,\n",
    "                f\"Now, try again. Invoke the CoderModel tool to structure the output with a steps_to_complete, files_to_create, file_path, code, license_text, project_status and call_next. you missed {missing_keys} in your previous response\"\n",
    "            ))\n",
    "        else:\n",
    "            state['coder_response'] = coder_solution['parsed']\n",
    "            state['file_path'] = coder_solution['parsed']['file_path']\n",
    "            state['files_to_create'] = coder_solution['parsed']['files_to_create']\n",
    "            state['code'] = coder_solution['parsed']['code']\n",
    "            state['license_text'] = coder_solution['parsed']['license_text']\n",
    "            state['project_status'] = coder_solution['parsed']['project_status']\n",
    "            state['call_next'] = coder_solution['parsed']['call_next']\n",
    "            coder_steps = re.split(r'\\d+\\.\\s',state['coder_response']['steps_to_complete'])\n",
    "            state['coder_steps'] = [coder_step.strip() for coder_step in coder_steps if coder_step!='']\n",
    "            state['curr_task_status'] = TaskState.PENDING.value\n",
    "\n",
    "    if (len(state['pending_tool_calls']) > 0):\n",
    "        state = set_curr_tool_call_from_pending_tool_calls(state)\n",
    "        curr_tool_call = get_curr_tool_call(state)\n",
    "        state = add_message(state, \n",
    "            AIMessage(\n",
    "                content=f\"make a tool_call to '{curr_tool_call['name']}'.\",\n",
    "                additional_kwargs={\n",
    "                    'tool_calls': [curr_tool_call],\n",
    "                },\n",
    "                tool_calls=[curr_tool_call],\n",
    "                response_metadata={'finish_reason': 'tool_calls'},\n",
    "            )\n",
    "        )\n",
    "    elif (get_next(state) == GraphNodes.CALL_TOOL.value) and (len(state['coder_steps']) > 0):\n",
    "        state['current_step'] = next_coder_step(state)\n",
    "\n",
    "        state = add_message(state, (\n",
    "            ChatRoles.USER.value,\n",
    "            state['current_step']\n",
    "        ))\n",
    "\n",
    "        temp_state = state.copy()\n",
    "        del temp_state['messages']\n",
    "\n",
    "        tool_selector = tool_chain.invoke({'context': f'{temp_state}', 'messages': get_messages_for_prompt(state)})\n",
    "\n",
    "        print(\"-----Tool Selector-------\")\n",
    "        pp.pp(tool_selector)\n",
    "        print(\"-----Tool Selector-------\")\n",
    "        try:\n",
    "            ToolChainValidator(content=tool_selector.content, tool_calls=tool_selector.tool_calls, additional_kwargs=tool_selector.additional_kwargs)\n",
    "\n",
    "            state['pending_tool_calls'] += tool_selector.tool_calls\n",
    "            state = set_curr_tool_call_from_pending_tool_calls(state)\n",
    "            curr_tool_call = get_curr_tool_call(state)\n",
    "\n",
    "            if curr_tool_call != {}:\n",
    "                state = add_message(state, \n",
    "                    AIMessage(\n",
    "                        content=f\"make a tool_call to '{curr_tool_call['name']}'.\",\n",
    "                        additional_kwargs={\n",
    "                            'tool_calls': [curr_tool_call],\n",
    "                        },\n",
    "                        tool_calls=[curr_tool_call],\n",
    "                        response_metadata={'finish_reason': 'tool_calls'},\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                print(\"something is wrong! \", curr_tool_call)\n",
    "\n",
    "            # (\n",
    "            #         ChatRoles.AI.value,\n",
    "            #         f\"make a tool_call to '{curr_tool_call['name']}' with args '{curr_tool_call['args']}'.\"\n",
    "            #     )\n",
    "            if state['iterations'] > 0:\n",
    "                state['iterations'] = 0\n",
    "        except Exception:\n",
    "                \n",
    "            if state['iterations'] >= state['max_retry']:\n",
    "                state['iterations'] = 0\n",
    "\n",
    "                state = add_message(state, (\n",
    "                    ChatRoles.USER.value,\n",
    "                    \"MaxRetriesError: Max Retries limit reached. Couldn't finish the step: \"\n",
    "                    f\" `{state['current_step']}`.\"\n",
    "                ))\n",
    "            else:\n",
    "                state = toggle_error(state)\n",
    "                state['iterations'] += 1\n",
    "                state['coder_steps'].insert(0, state['current_step'])\n",
    "                state['pending_tool_calls'] = []\n",
    "                \n",
    "                state = add_message(state, (\n",
    "                    ChatRoles.USER.value,\n",
    "                    \"UnexpectedScenarioOccured: It was unclear whether the tool chain couldn't\"\n",
    "                    \" find a suitable tool to complete the task or produced an unintended output\"\n",
    "                    \". An AIMessage with tool calls was expected to be added to the `tool_calls` field in AIMessage\" \n",
    "                    f\"Received: '{tool_selector}'. task:'{state['current_step']}'.\"\n",
    "                ))\n",
    "\n",
    "        print(\"DEAD END!!!\")\n",
    "        # if tool_selector.tool_calls:\n",
    "        #     if len(tool_selector.tool_calls) > 0:\n",
    "        #         state['pending_tool_calls'] += tool_selector.tool_calls\n",
    "            \n",
    "        #     state = set_curr_tool_call_from_pending_tool_calls(state)\n",
    "        #     curr_tool_call = get_curr_tool_call(state)\n",
    "        #     if curr_tool_call != {}:\n",
    "        #         state = add_message(state, (\n",
    "        #             ChatRoles.AI.value,\n",
    "        #             f\"make a tool_call to '{curr_tool_call['name']}' with args '{curr_tool_call['args']}'.\"\n",
    "        #         ))\n",
    "        # else: # Do I really need to reset the whole coder_steps after this?\n",
    "        #     # TODO->DONE(error, curr_task_status->New): NEED TO UPDATE few flags accordingly to detect this.\n",
    "        #     # TODO: This case might lead to a infinte loop.\n",
    "        #     # Think of the case where similiar task as the previous one is given to the tool_selector\n",
    "        #     # We will end up in this `else` case. even if the task is re structured we will end up in this case \n",
    "        #     # again and again.\n",
    "\n",
    "        #     # state = toggle_error(state)\n",
    "        #     # state['curr_task_status'] = TaskState.NEW.value\n",
    "\n",
    "        #     state = add_message(state, (\n",
    "        #         ChatRoles.USER.value,\n",
    "        #         f\"ERROR: '{tool_selector}' cannot be used to complete '{state['current_step']}' in the task, give an alternative or better breakdown of the task.\"\n",
    "        #     ))\n",
    "    else: # TODO: What if no tools were assigned? control directly came here?\n",
    "        state = add_message(state, (\n",
    "            ChatRoles.AI.value,\n",
    "            f\"The task: `{state['current_task']}` was successfully completed. All the steps:\"\n",
    "            f\" `{state['coder_response']['steps_to_complete']}` of the task have been addressed.\"\n",
    "            f\" The task status: `{TaskState.DONE.value}`, Are there any more tasks?\"\n",
    "        ))\n",
    "        state['curr_task_status'] = TaskState.AWAITING.value\n",
    "        state['call_next'] = \"\"\n",
    "        state['current_step'] = \"\"\n",
    "        state['current_task'] = \"\"\n",
    "        state['pending_tool_calls'] = []\n",
    "        state['coder_steps'] = []\n",
    "\n",
    "    return state\n",
    "\n",
    "def coder_router(state: GraphState) -> str:\n",
    "    \"\"\"\n",
    "    coder router\n",
    "    \"\"\"\n",
    "    if (get_next(state) == GraphNodes.CALL_TOOL.value) and get_curr_tool_call(state) != {}:\n",
    "        tool_name: str = get_curr_tool_call(state)['name']\n",
    "        return tool_name.upper()\n",
    "    \n",
    "    if state['error'] or len(state['pending_tool_calls']) > 0 or len(state['coder_steps']) > 0:\n",
    "        return GraphNodes.CODER.value\n",
    "    \n",
    "    # TODO: need to add check for new task assignment\n",
    "    if (state['project_status'] == TaskState.COMPLETED.value) or (state['curr_task_status'] == TaskState.AWAITING.value):\n",
    "        return GraphNodes.ARCHITECT.value\n",
    "    \n",
    "    return GraphNodes.CODER.value\n",
    "\n",
    "def download_license_file_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    download license file node \n",
    "    \"\"\"\n",
    "    \n",
    "    tool_call = get_curr_tool_call(state)\n",
    "\n",
    "    tool_name = tool_call['name']\n",
    "    tool_args = tool_call['args']\n",
    "    tool_call_id = tool_call['id']\n",
    "\n",
    "    action = ToolInvocation(\n",
    "        tool=tool_name,\n",
    "        tool_input=tool_args,\n",
    "    )\n",
    "    \n",
    "    response = coder_tools_executor.invoke(action)\n",
    "    state = add_message(state, \n",
    "        ToolMessage(\n",
    "            content=f\"{response}\",\n",
    "            name=tool_name,\n",
    "            tool_call_id=tool_call_id\n",
    "        )\n",
    "    )\n",
    "\n",
    "    state['curr_tool_call'] = {}\n",
    "    state['current_step'] = \"\"\n",
    "\n",
    "    return state\n",
    "\n",
    "def write_generated_code_to_file_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    write generated code to file node\n",
    "    \"\"\"\n",
    "\n",
    "    tool_call = get_curr_tool_call(state)\n",
    "\n",
    "    tool_name = tool_call['name']\n",
    "    tool_args = tool_call['args']\n",
    "    tool_call_id = tool_call['id']\n",
    "\n",
    "    action = ToolInvocation(\n",
    "        tool=tool_name,\n",
    "        tool_input=tool_args,\n",
    "    )\n",
    "    \n",
    "    response = coder_tools_executor.invoke(action)\n",
    "    # state = add_message(state, (ChatRoles.USER.value, f\"tool call response: {response}\"))\n",
    "    state = add_message(state, \n",
    "        ToolMessage(\n",
    "            content=f\"{response}\",\n",
    "            name=tool_name,\n",
    "            tool_call_id=tool_call_id\n",
    "        )\n",
    "    )\n",
    "\n",
    "    state['curr_tool_call'] = {}\n",
    "    state['current_step'] = \"\"\n",
    "\n",
    "    return state\n",
    "\n",
    "def create_git_repo_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    create git repo node\n",
    "    \"\"\"\n",
    "\n",
    "    tool_call = get_curr_tool_call(state)\n",
    "\n",
    "    tool_name = tool_call['name']\n",
    "    tool_args = tool_call['args']\n",
    "    tool_call_id = tool_call['id']\n",
    "\n",
    "    action = ToolInvocation(\n",
    "        tool=tool_name,\n",
    "        tool_input=tool_args,\n",
    "    )\n",
    "    \n",
    "    response = coder_tools_executor.invoke(action)\n",
    "    state = add_message(state, \n",
    "        ToolMessage(\n",
    "            content=f\"{response}\",\n",
    "            name=tool_name,\n",
    "            tool_call_id=tool_call_id\n",
    "        )\n",
    "    )\n",
    "\n",
    "    state['curr_tool_call'] = {}\n",
    "    state['current_step'] = \"\"\n",
    "\n",
    "    return state\n",
    "\n",
    "def execute_command_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    execute command node\n",
    "    \"\"\"\n",
    "\n",
    "    tool_call = get_curr_tool_call(state)\n",
    "\n",
    "    tool_name = tool_call['name']\n",
    "    tool_args = tool_call['args']\n",
    "    tool_call_id = tool_call['id']\n",
    "    \n",
    "    action = ToolInvocation(\n",
    "        tool=tool_name,\n",
    "        tool_input=tool_args,\n",
    "    )\n",
    "    \n",
    "    response = coder_tools_executor.invoke(action)\n",
    "    state = add_message(state, \n",
    "        ToolMessage(\n",
    "            content=f\"{response}\",\n",
    "            name=tool_name,\n",
    "            tool_call_id=tool_call_id\n",
    "        )\n",
    "    )\n",
    "\n",
    "    state['curr_tool_call'] = {}\n",
    "    state['current_step'] = \"\"\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need for Persistence\n",
    "In LangGraph, memory for maintaining context across interactions is facilitated via Checkpointers within StateGraphs.  \n",
    "1. When setting up a LangGraph workflow, you can ensure state persistence by employing a Checkpointer like `AsyncSqliteSaver`.  \n",
    "2. Simply include this in your workflow setup by calling `compile(checkpointer=my_checkpointer)` during graph compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable setup\n",
    "architect_str = GraphNodes.ARCHITECT.value\n",
    "coder_str = GraphNodes.CODER.value\n",
    "end_str = GraphNodes.END.value\n",
    "\n",
    "dlf_str = GraphNodes.DOWNLOAD_LICENSE_FILE.value\n",
    "wgcf_str = GraphNodes.WRITE_GENERATED_CODE_TO_FILE.value\n",
    "cgr_str = GraphNodes.CREATE_GIT_REPO.value\n",
    "ec_str = GraphNodes.EXECUTE_COMMAND.value\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# add all the node requied for the graph\n",
    "workflow.add_node(architect_str, architect_node)\n",
    "workflow.add_node(coder_str, coder_node)\n",
    "workflow.add_node(dlf_str, download_license_file_node)\n",
    "workflow.add_node(wgcf_str, write_generated_code_to_file_node)\n",
    "workflow.add_node(cgr_str, create_git_repo_node)\n",
    "workflow.add_node(ec_str, execute_command_node)\n",
    "\n",
    "# add edges for the graph\n",
    "workflow.add_conditional_edges(architect_str, architect_router, {\n",
    "    architect_str: architect_str,\n",
    "    coder_str: coder_str,\n",
    "    end_str: end_str\n",
    "})\n",
    "\n",
    "workflow.add_conditional_edges(coder_str, coder_router, {\n",
    "    architect_str: architect_str,\n",
    "    coder_str: coder_str,\n",
    "    dlf_str: dlf_str,\n",
    "    wgcf_str: wgcf_str,\n",
    "    cgr_str: cgr_str,\n",
    "    ec_str: ec_str\n",
    "})\n",
    "\n",
    "workflow.add_edge(wgcf_str, coder_str)\n",
    "workflow.add_edge(dlf_str, coder_str)\n",
    "workflow.add_edge(cgr_str, coder_str)\n",
    "workflow.add_edge(ec_str, coder_str)\n",
    "\n",
    "workflow.set_entry_point(architect_str)\n",
    "\n",
    "workflow_graph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow call graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    display(Image(workflow_graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inovke graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_input_json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m user_input, license_text \u001b[38;5;241m=\u001b[39m \u001b[43mread_input_json\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrest_api.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m new_state \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneration\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_retry\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     27\u001b[0m }\n\u001b[1;32m     28\u001b[0m events \u001b[38;5;241m=\u001b[39m workflow_graph\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m     29\u001b[0m     {   \n\u001b[1;32m     30\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_state,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     },\n\u001b[1;32m     45\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_input_json' is not defined"
     ]
    }
   ],
   "source": [
    "user_input, license_text = read_input_json(\"rest_api.json\")\n",
    "\n",
    "new_state = {\n",
    "    'error': False,\n",
    "    'generation': \"\",\n",
    "    'iterations': 0,\n",
    "    'curr_tool_call': {},\n",
    "    'curr_task_status': TaskState.NEW.value,\n",
    "    'current_step': \"\",\n",
    "\n",
    "    'project_name': \"\",\n",
    "    'requirements_overview': \"\",\n",
    "    'tasks': [],\n",
    "    'project_folder_structure': \"\",\n",
    "    'current_task': \"\",\n",
    "\n",
    "    'file_path': \"\",\n",
    "    'code': \"\",\n",
    "    'coder_steps': [],\n",
    "    'coder_response': \"\",\n",
    "    'pending_tool_calls': [],\n",
    "    'license_text': \"\",\n",
    "    \n",
    "    'project_status': TaskState.NEW.value,\n",
    "    'call_next': GraphNodes.NONE.value,\n",
    "    'max_retry': 2,\n",
    "}\n",
    "events = workflow_graph.stream(\n",
    "    {   \n",
    "        **new_state,\n",
    "        \"messages\": [\n",
    "            (   \"user\",\n",
    "                f\"Create this project for me in {PROJECT_PATH}.\" \n",
    "                f\"Requirements are {user_input}.\"\n",
    "                f\"{license_text} must be present at the top of each file created as part of the project.\" \n",
    "                \"Once you code it up, finish.\"\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    # Maximum number of steps to take in the graph and the thread ID to be used to persist the memory.\n",
    "    {\n",
    "        \"recursion_limit\": 200,\n",
    "        \"configurable\": {\"thread_id\": \"1\"}\n",
    "    },\n",
    ")\n",
    "\n",
    "for s in events:\n",
    "    pp.pp(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
