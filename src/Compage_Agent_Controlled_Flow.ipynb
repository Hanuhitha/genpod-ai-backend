{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervisor - Worker Controlled Flow for Gen Pod AI Backend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us import some basic libraries and load dotenv file, make sure it contains necessary API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pprint as pp\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading LLM\n",
    "We will load OpenAI GPT-4o LLM to assist our agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vkumar\\OneDrive - Imagevision.ai India Pvt Ltd\\Documents\\Projects\\Compage-Agents\\.venv\\Lib\\site-packages\\langchain_core\\utils\\utils.py:161: UserWarning: WARNING! seed is not default parameter.\n",
      "                seed was transferred to model_kwargs.\n",
      "                Please confirm that seed is what you intended.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vkumar\\OneDrive - Imagevision.ai India Pvt Ltd\\Documents\\Projects\\Compage-Agents\\.venv\\Lib\\site-packages\\langchain_core\\utils\\utils.py:161: UserWarning: WARNING! seed is not default parameter.\n",
      "                seed was transferred to model_kwargs.\n",
      "                Please confirm that seed is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# gpt-4o-2024-05-13\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-2024-05-13\", temperature=0, max_retries=5, streaming=True, seed=4000)\n",
    "code_llm = ChatOpenAI(model=\"gpt-4-turbo-2024-04-09\",temperature=0.3, max_retries=5, streaming=True, seed=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules Needed for this Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.schema import Document\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "# from langgraph.prebuilt import ToolExecutor, ToolInvocation\n",
    "import json\n",
    "# from langchain_core.agents import AgentAction, AgentFinish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us create some Utility function\n",
    "These function can help later on to read the input files as a json string and create agents that can be later used as nodes in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input_json(file_path) -> str:\n",
    "    \"\"\"Reads JSON data from a file and returns it as a string.\n",
    "\n",
    "    Args:\n",
    "        file_path: The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        A string representation of the JSON data.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as user_input_file:\n",
    "        data = json.load(user_input_file)\n",
    "    \n",
    "    user_input = json.dumps(data)\n",
    "    license_txt = data[\"LICENSE_TEXT\"]\n",
    "\n",
    "    return user_input, license_txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tools to be used by Agents\n",
    "These tools are custom fuctions that will also go as nodes in the graph and will be called by the agent to take some action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this path to your local directory where you want to create the project at.\n",
    "PROJECT_PATH = \"path/for/your/project/to/be/created\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool, StructuredTool\n",
    "from typing import Annotated\n",
    "import os\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "\n",
    "@tool \n",
    "def write_generated_code_to_file(\n",
    "    generated_code: Annotated[str, \"The code generated by the agent.\"],\n",
    "    file_path: Annotated[str, \"Absolute path where the generated code should be written can handle directory create if does not exist.\"]\n",
    "    # license_txt: Annotated[str, \"License txt provided by user to add to each src file.\"]\n",
    "):\n",
    "# project_folder: Annotated[str, \"The name of the project where all files needed for the project are to placed.\"]\n",
    "    \"\"\"\n",
    "    Writes the provided generated code to the specified file within the project structure.\n",
    "\n",
    "    Args:\n",
    "        generated_code (str): The code generated by the agent.\n",
    "        file_path (str): The path where the generated code should be written.\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        # Ensure the directory exists before writing the file\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        \n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(generated_code)\n",
    "        \n",
    "        return {'project_files':file_path}, f\"Successfully wrote the generated code to: {file_path}\"\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to write generated code. Error: {repr(e)}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from typing import Annotated\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def create_git_repo(project_name: Annotated[str, \"Name of the new Git repository that should be created.\"], repo_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Creates a new Git repository at the specified path.\n",
    "\n",
    "    Args:\n",
    "        project_name (str): Name of the new Git repository that should be created.\n",
    "        PROJECT_PATH (str): Path where the new Git repository will be created.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the path of the newly created Git repository or an error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        repo_path = os.path.join(PROJECT_PATH, project_name)\n",
    "        \n",
    "        # Ensure the directory exists before initializing the Git repository\n",
    "        os.makedirs(repo_path, exist_ok=True)\n",
    "        \n",
    "        # check_path = os.path.join(repo_path, \".git\")\n",
    "        # Check if the directory is already a Git repository\n",
    "        # if os.path.exists(check_path):\n",
    "        #     return f\"Project is already a git repository: {repr(e)}\"\n",
    "        \n",
    "        subprocess.check_output(['git', 'init'], cwd=repo_path)\n",
    "        \n",
    "        return {'repo_path': repo_path}, f\"Git repository created successfully: {repo_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Failed to create a new Git repository. Error: {repr(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from typing import Annotated\n",
    "from langchain.tools import tool\n",
    "\n",
    "ALLOWED_COMMANDS = ['mkdir', 'docker', 'python', 'python3', 'pip', 'virtualenv', 'mv', 'pytest']\n",
    "\n",
    "@tool\n",
    "def execute_command(\n",
    "    command: Annotated[str, \"The complete set of commands to be executed on the local machine in order.\"],\n",
    "    repo_path: Annotated[str,\"Path where the repository is created.\"]\n",
    "):\n",
    "    \"\"\"\n",
    "    Executes a command on the local machine.\n",
    "\n",
    "    Args:\n",
    "        command (str): The complete set of commands to be executed on the local machine in order.\n",
    "    \"\"\"\n",
    "    # Split the command into parts\n",
    "    parts = command.split()\n",
    "    \n",
    "    # Check if the command is in the whitelist\n",
    "    if parts[0] not in ALLOWED_COMMANDS:\n",
    "        return f\"Command '{parts[0]}' is not allowed.\"\n",
    "    \n",
    "    try:\n",
    "        # Execute the command\n",
    "        # full_path = os.path.join(PROJECT_PATH,repo_path)\n",
    "        additional_command = f\"cd {repo_path} && \"\n",
    "        updated_command = additional_command + command\n",
    "        result = subprocess.check_output(updated_command, shell=True)\n",
    "        \n",
    "        return f\"Command executed successfully. Output: {result}\"\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute command. Error: {repr(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Annotated, List\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def check_files_created(\n",
    "    files: Annotated[List[str], \"The list of files that should be present in the project repository.\"],\n",
    "    repo_path: Annotated[str, \"Absolute Path where the repository is created.\"]\n",
    "):\n",
    "    \"\"\"\n",
    "    Checks if all the specified files within a folder structure are created or not.\n",
    "\n",
    "    Args:\n",
    "        files (List[str]): The list of files to check.\n",
    "    \"\"\"\n",
    "    missing_files = []\n",
    "    \n",
    "    # Check each file\n",
    "    for file in files:\n",
    "        full_file_path = os.path.join(repo_path, file)\n",
    "        \n",
    "        # Directly check if the file exists without executing shell commands\n",
    "        if not os.path.exists(full_file_path):\n",
    "            missing_files.append(file)\n",
    "    \n",
    "    if missing_files:\n",
    "        return {\"missing_files\":missing_files}, f\"missing these files: {missing_files}\"\n",
    "    else:\n",
    "        return \"All files are present.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Annotated, List\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def verify_file_content(\n",
    "    files: Annotated[List[str], \"The list of files that should be present in the project repository.\"],\n",
    "    repo_path: Annotated[str, \"Absolute Path where the repository is created.\"]\n",
    "):\n",
    "    \"\"\"\n",
    "    Checks if all the specified files within a folder structure are empty or not.\n",
    "\n",
    "    Args:\n",
    "        files (List[str]): The list of files to check.\n",
    "    \"\"\"\n",
    "    empty_files = []\n",
    "    \n",
    "    # Check each file\n",
    "    for file in files:\n",
    "        full_file_path = os.path.join(repo_path, file)\n",
    "        \n",
    "        # Check if the file exists and is empty\n",
    "        if os.path.exists(full_file_path) and os.path.getsize(full_file_path) == 0:\n",
    "            empty_files.append(file)\n",
    "    \n",
    "    if empty_files:\n",
    "        return f\"These files are empty: {empty_files}\"\n",
    "    else:\n",
    "        return \"All files are not empty.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from typing import Annotated\n",
    "\n",
    "@tool\n",
    "def download_license_file(\n",
    "        url: Annotated[str, \"LICENSE_URL from where it has to be downloaded.\"],\n",
    "        file_path: Annotated[str, \"Absolute path where the License.md should be written can handle directory create if does not exist.\"]\n",
    " ) -> str:\n",
    "    \"\"\"\n",
    "    Downloads a license file from a given URL and saves it locally.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL of the license file.\n",
    "    file_path (str): Absolute path where the generated code should be written can handle directory create if does not exist.\n",
    "    \n",
    "    Returns:\n",
    "    str: The local path where the file was saved.\n",
    "    \"\"\"\n",
    "    import pprint as pp\n",
    "    response = requests.get(url)\n",
    "    # print(response.content)\n",
    "    # response.raise_for_status()  # Raise exception if the request failed\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        return f\"Successfully wrote the License to {file_path}\"\n",
    "\n",
    "    except:\n",
    "        return f\"failed to write the License to {file_path}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's us define a Data model that we can use to update the call's in the graph plus also to define a schema of response from the llm's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, ClassVar\n",
    "\n",
    "class RequirementsDoc(BaseModel):\n",
    "    \"\"\"Requirements Document output\"\"\"\n",
    "\n",
    "    project_name: str = Field(description=\"Project name that the user has assigned you to work on\")\n",
    "    well_documented: str = Field(description=\"Well built requirements document from the user input\")\n",
    "    tasks: str = Field(description=\"Spilt the detailed requirements into independent task with as much context as possible that are crucial to follow during completion\")\n",
    "    project_folder_structure: str = Field(description=\"Project folder structure to follow.\")\n",
    "    next_task: str = Field(description=\"Next Task to do with all the functional and non functional details related to that task\")\n",
    "    # deliverables: Dict[str, str] = Field(default_factory=dict, description=\"A seperate Dictionary of Tasks and their corresponding details for completion\")\n",
    "    description: ClassVar[str] = \"Schema of what all documents should be generated.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vkumar\\OneDrive - Imagevision.ai India Pvt Ltd\\Documents\\Projects\\Compage-Agents\\.venv\\Lib\\site-packages\\langchain_core\\_api\\beta_decorator.py:87: LangChainBetaWarning: The method `ChatOpenAI.with_structured_output` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "import json\n",
    "architect_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "    \n",
    "            \"\"\"<instructions> You are a Development Lead in charge of implementing the given project. Thoroughly analyze the user input and build a thorough requirements document needed to implement the project. \n",
    "            You should also be able to break them into independent tasks that can be assigned to other team memeber.\\\n",
    "            Enforce the use of microservice architecture, Best practices Project Folder structure, 12-factor application standards,\\\n",
    "            domain-driven microservice application design, clean-code development architecture standards in the requirements document\\\n",
    "            Final project should include all the source files, configuration files, unit test files, OpenAPI specfile for the project in YAML, License.md file from the User provided URL, a Requirements.txt file, Dockerfile, gitignore and a dockerignore file.\n",
    "            Structure your answer: \n",
    "            1) pick the project name from the user input, \n",
    "            2) A well defined complete requirements document, \n",
    "            3) Separate the tasks that are required to be completed in the project with all the functional and nonfunctional requirements needed to perform the task smoothly. \n",
    "            4) Project_folder_structure to be enforced for the project \n",
    "            5) What should be the next task if we decide to start working on the project.\\n\n",
    "            Invoke the Requirements_Doc tool to structure the output correctly. </instructions> \\n Here is the user question:\"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# First lets read in the input that defines the task to be performed by the multi agent setup\n",
    "user_input, license_text = read_input_json(\"rest_api.json\")\n",
    "architect_llm = llm.with_structured_output(RequirementsDoc, include_raw=True)\n",
    "\n",
    "architect_chain = architect_prompt | llm.with_structured_output(RequirementsDoc, include_raw=True)\n",
    "question = f\"Let's build this Project, here are the user requirements are {user_input}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw': AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_g6Sq6WRl9MvYKey7LvTeIs2j', 'function': {'arguments': '{\"project_name\":\"user-service\",\"well_documented\":\"# Project Name: user-service\\\\n\\\\n## Overview\\\\nThe `user-service` project is a REST API service built using Python and the FastAPI framework. The service will manage user data with CRUD operations and will be instrumented with the latest version of the OpenTelemetry SDK for observability. The service will interact with a MySQL database and will run on port 3000.\\\\n\\\\n## Functional Requirements\\\\n1. **User Resource**:\\\\n    - **POST /users**: Create a new user.\\\\n    - **GET /users**: List all users.\\\\n    - **GET /users/{id}**: Get a specific user by ID.\\\\n    - **PUT /users/{id}**: Update a specific user by ID.\\\\n    - **DELETE /users/{id}**: Delete a specific user by ID.\\\\n\\\\n2. **Fields for User Resource**:\\\\n    - Name (string)\\\\n    - City (string)\\\\n\\\\n3. **Database**:\\\\n    - Use MySQL for data storage.\\\\n\\\\n4. **Observability**:\\\\n    - Integrate with OpenTelemetry SDK to send data to the OpenTelemetry collector agent.\\\\n\\\\n## Non-Functional Requirements\\\\n1. **Performance**: The API should be able to handle a high number of requests per second.\\\\n2. **Scalability**: The service should be easily scalable.\\\\n3. **Security**: Implement authentication and authorization mechanisms.\\\\n4. **Documentation**: Provide API documentation using OpenAPI.\\\\n5. **Testing**: Implement unit and integration tests.\\\\n6. **Licensing**: Include the provided LICENSE file and text.\\\\n\\\\n## Tasks\\\\n1. **Setup Project Structure**\\\\n    - Create a new FastAPI project.\\\\n    - Set up the project folder structure.\\\\n\\\\n2. **Database Integration**\\\\n    - Configure MySQL database connection.\\\\n    - Create database models for the User resource.\\\\n\\\\n3. **API Endpoints**\\\\n    - Implement CRUD operations for the User resource.\\\\n\\\\n4. **Observability**\\\\n    - Integrate OpenTelemetry SDK.\\\\n    - Configure the service to send data to the OpenTelemetry collector agent.\\\\n\\\\n5. **Documentation**\\\\n    - Generate OpenAPI spec file.\\\\n    - Write API documentation.\\\\n\\\\n6. **Testing**\\\\n    - Write unit tests for each endpoint.\\\\n    - Write integration tests.\\\\n\\\\n7. **Licensing**\\\\n    - Add LICENSE file from the provided URL.\\\\n    - Include the provided LICENSE text in the project.\\\\n\\\\n8. **Containerization**\\\\n    - Write a Dockerfile for the service.\\\\n    - Create a docker-compose file if necessary.\\\\n\\\\n## Project Folder Structure\\\\n```\\\\nuser-service/\\\\n├── app/\\\\n│   ├── __init__.py\\\\n│   ├── main.py\\\\n│   ├── api/\\\\n│   │   ├── __init__.py\\\\n│   │   ├── v1/\\\\n│   │   │   ├── __init__.py\\\\n│   │   │   ├── endpoints/\\\\n│   │   │   │   ├── __init__.py\\\\n│   │   │   │   ├── user.py\\\\n│   ├── core/\\\\n│   │   ├── __init__.py\\\\n│   │   ├── config.py\\\\n│   │   ├── database.py\\\\n│   ├── models/\\\\n│   │   ├── __init__.py\\\\n│   │   ├── user.py\\\\n│   ├── schemas/\\\\n│   │   ├── __init__.py\\\\n│   │   ├── user.py\\\\n│   ├── services/\\\\n│   │   ├── __init__.py\\\\n│   │   ├── user_service.py\\\\n│   ├── tests/\\\\n│   │   ├── __init__.py\\\\n│   │   ├── test_user.py\\\\n├── .gitignore\\\\n├── .dockerignore\\\\n├── Dockerfile\\\\n├── requirements.txt\\\\n├── openapi.yaml\\\\n├── LICENSE\\\\n```\\\\n\\\\n## Next Task\\\\nThe next task is to set up the initial project structure and configure the FastAPI framework.\",\"tasks\":\"1. **Setup Project Structure**\\\\n    - Create a new FastAPI project.\\\\n    - Set up the project folder structure.\\\\n\\\\n2. **Database Integration**\\\\n    - Configure MySQL database connection.\\\\n    - Create database models for the User resource.\\\\n\\\\n3. **API Endpoints**\\\\n    - Implement CRUD operations for the User resource.\\\\n\\\\n4. **Observability**\\\\n    - Integrate OpenTelemetry SDK.\\\\n    - Configure the service to send data to the OpenTelemetry collector agent.\\\\n\\\\n5. **Documentation**\\\\n    - Generate OpenAPI spec file.\\\\n    - Write API documentation.\\\\n\\\\n6. **Testing**\\\\n    - Write unit tests for each endpoint.\\\\n    - Write integration tests.\\\\n\\\\n7. **Licensing**\\\\n    - Add LICENSE file from the provided URL.\\\\n    - Include the provided LICENSE text in the project.\\\\n\\\\n8. **Containerization**\\\\n    - Write a Dockerfile for the service.\\\\n    - Create a docker-compose file if necessary.\",\"project_folder_structure\":\"user-service/\\\\n├── app/\\\\n│   ├── __init__.py\\\\n│   ├── main.py\\\\n│   ├── api/\\\\n│   │   ├── __init__.py\\\\n│   │   ├── v1/\\\\n│   │   │   ├── __init__.py\\\\n│   │   │   ├── endpoints/\\\\n│   │   │   │   ├── __init__.py\\\\n│   │   │   │   ├── user.py\\\\n│   ├── core/\\\\n│   │   ├── __init__.py\\\\n│   │   ├── config.py\\\\n│   │   ├── database.py\\\\n│   ├── models/\\\\n│   │   ├── __init__.py\\\\n│   │   ├── user.py\\\\n│   ├── schemas/\\\\n│   │   ├── __init__.py\\\\n│   │   ├── user.py\\\\n│   ├── services/\\\\n│   │   ├── __init__.py\\\\n│   │   ├── user_service.py\\\\n│   ├── tests/\\\\n│   │   ├── __init__.py\\\\n│   │   ├── test_user.py\\\\n├── .gitignore\\\\n├── .dockerignore\\\\n├── Dockerfile\\\\n├── requirements.txt\\\\n├── openapi.yaml\\\\n├── LICENSE\",\"next_task\":\"The next task is to set up the initial project structure and configure the FastAPI framework.\"}', 'name': 'RequirementsDoc'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'stop'}, id='run-fbe46f5c-8903-4e56-b11c-443db659e84e-0', tool_calls=[{'name': 'RequirementsDoc', 'args': {'project_name': 'user-service', 'well_documented': '# Project Name: user-service\\n\\n## Overview\\nThe `user-service` project is a REST API service built using Python and the FastAPI framework. The service will manage user data with CRUD operations and will be instrumented with the latest version of the OpenTelemetry SDK for observability. The service will interact with a MySQL database and will run on port 3000.\\n\\n## Functional Requirements\\n1. **User Resource**:\\n    - **POST /users**: Create a new user.\\n    - **GET /users**: List all users.\\n    - **GET /users/{id}**: Get a specific user by ID.\\n    - **PUT /users/{id}**: Update a specific user by ID.\\n    - **DELETE /users/{id}**: Delete a specific user by ID.\\n\\n2. **Fields for User Resource**:\\n    - Name (string)\\n    - City (string)\\n\\n3. **Database**:\\n    - Use MySQL for data storage.\\n\\n4. **Observability**:\\n    - Integrate with OpenTelemetry SDK to send data to the OpenTelemetry collector agent.\\n\\n## Non-Functional Requirements\\n1. **Performance**: The API should be able to handle a high number of requests per second.\\n2. **Scalability**: The service should be easily scalable.\\n3. **Security**: Implement authentication and authorization mechanisms.\\n4. **Documentation**: Provide API documentation using OpenAPI.\\n5. **Testing**: Implement unit and integration tests.\\n6. **Licensing**: Include the provided LICENSE file and text.\\n\\n## Tasks\\n1. **Setup Project Structure**\\n    - Create a new FastAPI project.\\n    - Set up the project folder structure.\\n\\n2. **Database Integration**\\n    - Configure MySQL database connection.\\n    - Create database models for the User resource.\\n\\n3. **API Endpoints**\\n    - Implement CRUD operations for the User resource.\\n\\n4. **Observability**\\n    - Integrate OpenTelemetry SDK.\\n    - Configure the service to send data to the OpenTelemetry collector agent.\\n\\n5. **Documentation**\\n    - Generate OpenAPI spec file.\\n    - Write API documentation.\\n\\n6. **Testing**\\n    - Write unit tests for each endpoint.\\n    - Write integration tests.\\n\\n7. **Licensing**\\n    - Add LICENSE file from the provided URL.\\n    - Include the provided LICENSE text in the project.\\n\\n8. **Containerization**\\n    - Write a Dockerfile for the service.\\n    - Create a docker-compose file if necessary.\\n\\n## Project Folder Structure\\n```\\nuser-service/\\n├── app/\\n│   ├── __init__.py\\n│   ├── main.py\\n│   ├── api/\\n│   │   ├── __init__.py\\n│   │   ├── v1/\\n│   │   │   ├── __init__.py\\n│   │   │   ├── endpoints/\\n│   │   │   │   ├── __init__.py\\n│   │   │   │   ├── user.py\\n│   ├── core/\\n│   │   ├── __init__.py\\n│   │   ├── config.py\\n│   │   ├── database.py\\n│   ├── models/\\n│   │   ├── __init__.py\\n│   │   ├── user.py\\n│   ├── schemas/\\n│   │   ├── __init__.py\\n│   │   ├── user.py\\n│   ├── services/\\n│   │   ├── __init__.py\\n│   │   ├── user_service.py\\n│   ├── tests/\\n│   │   ├── __init__.py\\n│   │   ├── test_user.py\\n├── .gitignore\\n├── .dockerignore\\n├── Dockerfile\\n├── requirements.txt\\n├── openapi.yaml\\n├── LICENSE\\n```\\n\\n## Next Task\\nThe next task is to set up the initial project structure and configure the FastAPI framework.', 'tasks': '1. **Setup Project Structure**\\n    - Create a new FastAPI project.\\n    - Set up the project folder structure.\\n\\n2. **Database Integration**\\n    - Configure MySQL database connection.\\n    - Create database models for the User resource.\\n\\n3. **API Endpoints**\\n    - Implement CRUD operations for the User resource.\\n\\n4. **Observability**\\n    - Integrate OpenTelemetry SDK.\\n    - Configure the service to send data to the OpenTelemetry collector agent.\\n\\n5. **Documentation**\\n    - Generate OpenAPI spec file.\\n    - Write API documentation.\\n\\n6. **Testing**\\n    - Write unit tests for each endpoint.\\n    - Write integration tests.\\n\\n7. **Licensing**\\n    - Add LICENSE file from the provided URL.\\n    - Include the provided LICENSE text in the project.\\n\\n8. **Containerization**\\n    - Write a Dockerfile for the service.\\n    - Create a docker-compose file if necessary.', 'project_folder_structure': 'user-service/\\n├── app/\\n│   ├── __init__.py\\n│   ├── main.py\\n│   ├── api/\\n│   │   ├── __init__.py\\n│   │   ├── v1/\\n│   │   │   ├── __init__.py\\n│   │   │   ├── endpoints/\\n│   │   │   │   ├── __init__.py\\n│   │   │   │   ├── user.py\\n│   ├── core/\\n│   │   ├── __init__.py\\n│   │   ├── config.py\\n│   │   ├── database.py\\n│   ├── models/\\n│   │   ├── __init__.py\\n│   │   ├── user.py\\n│   ├── schemas/\\n│   │   ├── __init__.py\\n│   │   ├── user.py\\n│   ├── services/\\n│   │   ├── __init__.py\\n│   │   ├── user_service.py\\n│   ├── tests/\\n│   │   ├── __init__.py\\n│   │   ├── test_user.py\\n├── .gitignore\\n├── .dockerignore\\n├── Dockerfile\\n├── requirements.txt\\n├── openapi.yaml\\n├── LICENSE', 'next_task': 'The next task is to set up the initial project structure and configure the FastAPI framework.'}, 'id': 'call_g6Sq6WRl9MvYKey7LvTeIs2j'}]),\n",
       " 'parsed': {'project_name': 'user-service',\n",
       "  'well_documented': '# Project Name: user-service\\n\\n## Overview\\nThe `user-service` project is a REST API service built using Python and the FastAPI framework. The service will manage user data with CRUD operations and will be instrumented with the latest version of the OpenTelemetry SDK for observability. The service will interact with a MySQL database and will run on port 3000.\\n\\n## Functional Requirements\\n1. **User Resource**:\\n    - **POST /users**: Create a new user.\\n    - **GET /users**: List all users.\\n    - **GET /users/{id}**: Get a specific user by ID.\\n    - **PUT /users/{id}**: Update a specific user by ID.\\n    - **DELETE /users/{id}**: Delete a specific user by ID.\\n\\n2. **Fields for User Resource**:\\n    - Name (string)\\n    - City (string)\\n\\n3. **Database**:\\n    - Use MySQL for data storage.\\n\\n4. **Observability**:\\n    - Integrate with OpenTelemetry SDK to send data to the OpenTelemetry collector agent.\\n\\n## Non-Functional Requirements\\n1. **Performance**: The API should be able to handle a high number of requests per second.\\n2. **Scalability**: The service should be easily scalable.\\n3. **Security**: Implement authentication and authorization mechanisms.\\n4. **Documentation**: Provide API documentation using OpenAPI.\\n5. **Testing**: Implement unit and integration tests.\\n6. **Licensing**: Include the provided LICENSE file and text.\\n\\n## Tasks\\n1. **Setup Project Structure**\\n    - Create a new FastAPI project.\\n    - Set up the project folder structure.\\n\\n2. **Database Integration**\\n    - Configure MySQL database connection.\\n    - Create database models for the User resource.\\n\\n3. **API Endpoints**\\n    - Implement CRUD operations for the User resource.\\n\\n4. **Observability**\\n    - Integrate OpenTelemetry SDK.\\n    - Configure the service to send data to the OpenTelemetry collector agent.\\n\\n5. **Documentation**\\n    - Generate OpenAPI spec file.\\n    - Write API documentation.\\n\\n6. **Testing**\\n    - Write unit tests for each endpoint.\\n    - Write integration tests.\\n\\n7. **Licensing**\\n    - Add LICENSE file from the provided URL.\\n    - Include the provided LICENSE text in the project.\\n\\n8. **Containerization**\\n    - Write a Dockerfile for the service.\\n    - Create a docker-compose file if necessary.\\n\\n## Project Folder Structure\\n```\\nuser-service/\\n├── app/\\n│   ├── __init__.py\\n│   ├── main.py\\n│   ├── api/\\n│   │   ├── __init__.py\\n│   │   ├── v1/\\n│   │   │   ├── __init__.py\\n│   │   │   ├── endpoints/\\n│   │   │   │   ├── __init__.py\\n│   │   │   │   ├── user.py\\n│   ├── core/\\n│   │   ├── __init__.py\\n│   │   ├── config.py\\n│   │   ├── database.py\\n│   ├── models/\\n│   │   ├── __init__.py\\n│   │   ├── user.py\\n│   ├── schemas/\\n│   │   ├── __init__.py\\n│   │   ├── user.py\\n│   ├── services/\\n│   │   ├── __init__.py\\n│   │   ├── user_service.py\\n│   ├── tests/\\n│   │   ├── __init__.py\\n│   │   ├── test_user.py\\n├── .gitignore\\n├── .dockerignore\\n├── Dockerfile\\n├── requirements.txt\\n├── openapi.yaml\\n├── LICENSE\\n```\\n\\n## Next Task\\nThe next task is to set up the initial project structure and configure the FastAPI framework.',\n",
       "  'tasks': '1. **Setup Project Structure**\\n    - Create a new FastAPI project.\\n    - Set up the project folder structure.\\n\\n2. **Database Integration**\\n    - Configure MySQL database connection.\\n    - Create database models for the User resource.\\n\\n3. **API Endpoints**\\n    - Implement CRUD operations for the User resource.\\n\\n4. **Observability**\\n    - Integrate OpenTelemetry SDK.\\n    - Configure the service to send data to the OpenTelemetry collector agent.\\n\\n5. **Documentation**\\n    - Generate OpenAPI spec file.\\n    - Write API documentation.\\n\\n6. **Testing**\\n    - Write unit tests for each endpoint.\\n    - Write integration tests.\\n\\n7. **Licensing**\\n    - Add LICENSE file from the provided URL.\\n    - Include the provided LICENSE text in the project.\\n\\n8. **Containerization**\\n    - Write a Dockerfile for the service.\\n    - Create a docker-compose file if necessary.',\n",
       "  'project_folder_structure': 'user-service/\\n├── app/\\n│   ├── __init__.py\\n│   ├── main.py\\n│   ├── api/\\n│   │   ├── __init__.py\\n│   │   ├── v1/\\n│   │   │   ├── __init__.py\\n│   │   │   ├── endpoints/\\n│   │   │   │   ├── __init__.py\\n│   │   │   │   ├── user.py\\n│   ├── core/\\n│   │   ├── __init__.py\\n│   │   ├── config.py\\n│   │   ├── database.py\\n│   ├── models/\\n│   │   ├── __init__.py\\n│   │   ├── user.py\\n│   ├── schemas/\\n│   │   ├── __init__.py\\n│   │   ├── user.py\\n│   ├── services/\\n│   │   ├── __init__.py\\n│   │   ├── user_service.py\\n│   ├── tests/\\n│   │   ├── __init__.py\\n│   │   ├── test_user.py\\n├── .gitignore\\n├── .dockerignore\\n├── Dockerfile\\n├── requirements.txt\\n├── openapi.yaml\\n├── LICENSE',\n",
       "  'next_task': 'The next task is to set up the initial project structure and configure the FastAPI framework.'},\n",
       " 'parsing_error': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = f\"Let's build this Project, here are the user requirements are {user_input}.\"\n",
    "solution = architect_chain.invoke({\"messages\":[(\"user\",question)]})\n",
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'project_name': 'user-service',\n",
      " 'well_documented': '# Project Name: user-service\\n'\n",
      "                    '\\n'\n",
      "                    '## Overview\\n'\n",
      "                    'The `user-service` project is a REST API service built '\n",
      "                    'using Python and the FastAPI framework. The service will '\n",
      "                    'manage user data with CRUD operations and will be '\n",
      "                    'instrumented with the latest version of the OpenTelemetry '\n",
      "                    'SDK for observability. The service will interact with a '\n",
      "                    'MySQL database and will run on port 3000.\\n'\n",
      "                    '\\n'\n",
      "                    '## Functional Requirements\\n'\n",
      "                    '1. **User Resource**:\\n'\n",
      "                    '    - **POST /users**: Create a new user.\\n'\n",
      "                    '    - **GET /users**: List all users.\\n'\n",
      "                    '    - **GET /users/{id}**: Get a specific user by ID.\\n'\n",
      "                    '    - **PUT /users/{id}**: Update a specific user by ID.\\n'\n",
      "                    '    - **DELETE /users/{id}**: Delete a specific user by '\n",
      "                    'ID.\\n'\n",
      "                    '\\n'\n",
      "                    '2. **Fields for User Resource**:\\n'\n",
      "                    '    - Name (string)\\n'\n",
      "                    '    - City (string)\\n'\n",
      "                    '\\n'\n",
      "                    '3. **Database**:\\n'\n",
      "                    '    - Use MySQL for data storage.\\n'\n",
      "                    '\\n'\n",
      "                    '4. **Observability**:\\n'\n",
      "                    '    - Integrate with OpenTelemetry SDK to send data to '\n",
      "                    'the OpenTelemetry collector agent.\\n'\n",
      "                    '\\n'\n",
      "                    '## Non-Functional Requirements\\n'\n",
      "                    '1. **Performance**: The API should be able to handle a '\n",
      "                    'high number of requests per second.\\n'\n",
      "                    '2. **Scalability**: The service should be easily '\n",
      "                    'scalable.\\n'\n",
      "                    '3. **Security**: Implement authentication and '\n",
      "                    'authorization mechanisms.\\n'\n",
      "                    '4. **Documentation**: Provide API documentation using '\n",
      "                    'OpenAPI.\\n'\n",
      "                    '5. **Testing**: Implement unit and integration tests.\\n'\n",
      "                    '6. **Licensing**: Include the provided LICENSE file and '\n",
      "                    'text.\\n'\n",
      "                    '\\n'\n",
      "                    '## Tasks\\n'\n",
      "                    '1. **Setup Project Structure**\\n'\n",
      "                    '    - Create a new FastAPI project.\\n'\n",
      "                    '    - Set up the project folder structure.\\n'\n",
      "                    '\\n'\n",
      "                    '2. **Database Integration**\\n'\n",
      "                    '    - Configure MySQL database connection.\\n'\n",
      "                    '    - Create database models for the User resource.\\n'\n",
      "                    '\\n'\n",
      "                    '3. **API Endpoints**\\n'\n",
      "                    '    - Implement CRUD operations for the User resource.\\n'\n",
      "                    '\\n'\n",
      "                    '4. **Observability**\\n'\n",
      "                    '    - Integrate OpenTelemetry SDK.\\n'\n",
      "                    '    - Configure the service to send data to the '\n",
      "                    'OpenTelemetry collector agent.\\n'\n",
      "                    '\\n'\n",
      "                    '5. **Documentation**\\n'\n",
      "                    '    - Generate OpenAPI spec file.\\n'\n",
      "                    '    - Write API documentation.\\n'\n",
      "                    '\\n'\n",
      "                    '6. **Testing**\\n'\n",
      "                    '    - Write unit tests for each endpoint.\\n'\n",
      "                    '    - Write integration tests.\\n'\n",
      "                    '\\n'\n",
      "                    '7. **Licensing**\\n'\n",
      "                    '    - Add LICENSE file from the provided URL.\\n'\n",
      "                    '    - Include the provided LICENSE text in the project.\\n'\n",
      "                    '\\n'\n",
      "                    '8. **Containerization**\\n'\n",
      "                    '    - Write a Dockerfile for the service.\\n'\n",
      "                    '    - Create a docker-compose file if necessary.\\n'\n",
      "                    '\\n'\n",
      "                    '## Project Folder Structure\\n'\n",
      "                    '```\\n'\n",
      "                    'user-service/\\n'\n",
      "                    '├── app/\\n'\n",
      "                    '│   ├── __init__.py\\n'\n",
      "                    '│   ├── main.py\\n'\n",
      "                    '│   ├── api/\\n'\n",
      "                    '│   │   ├── __init__.py\\n'\n",
      "                    '│   │   ├── v1/\\n'\n",
      "                    '│   │   │   ├── __init__.py\\n'\n",
      "                    '│   │   │   ├── endpoints/\\n'\n",
      "                    '│   │   │   │   ├── __init__.py\\n'\n",
      "                    '│   │   │   │   ├── user.py\\n'\n",
      "                    '│   ├── core/\\n'\n",
      "                    '│   │   ├── __init__.py\\n'\n",
      "                    '│   │   ├── config.py\\n'\n",
      "                    '│   │   ├── database.py\\n'\n",
      "                    '│   ├── models/\\n'\n",
      "                    '│   │   ├── __init__.py\\n'\n",
      "                    '│   │   ├── user.py\\n'\n",
      "                    '│   ├── schemas/\\n'\n",
      "                    '│   │   ├── __init__.py\\n'\n",
      "                    '│   │   ├── user.py\\n'\n",
      "                    '│   ├── services/\\n'\n",
      "                    '│   │   ├── __init__.py\\n'\n",
      "                    '│   │   ├── user_service.py\\n'\n",
      "                    '│   ├── tests/\\n'\n",
      "                    '│   │   ├── __init__.py\\n'\n",
      "                    '│   │   ├── test_user.py\\n'\n",
      "                    '├── .gitignore\\n'\n",
      "                    '├── .dockerignore\\n'\n",
      "                    '├── Dockerfile\\n'\n",
      "                    '├── requirements.txt\\n'\n",
      "                    '├── openapi.yaml\\n'\n",
      "                    '├── LICENSE\\n'\n",
      "                    '```\\n'\n",
      "                    '\\n'\n",
      "                    '## Next Task\\n'\n",
      "                    'The next task is to set up the initial project structure '\n",
      "                    'and configure the FastAPI framework.',\n",
      " 'tasks': '1. **Setup Project Structure**\\n'\n",
      "          '    - Create a new FastAPI project.\\n'\n",
      "          '    - Set up the project folder structure.\\n'\n",
      "          '\\n'\n",
      "          '2. **Database Integration**\\n'\n",
      "          '    - Configure MySQL database connection.\\n'\n",
      "          '    - Create database models for the User resource.\\n'\n",
      "          '\\n'\n",
      "          '3. **API Endpoints**\\n'\n",
      "          '    - Implement CRUD operations for the User resource.\\n'\n",
      "          '\\n'\n",
      "          '4. **Observability**\\n'\n",
      "          '    - Integrate OpenTelemetry SDK.\\n'\n",
      "          '    - Configure the service to send data to the OpenTelemetry '\n",
      "          'collector agent.\\n'\n",
      "          '\\n'\n",
      "          '5. **Documentation**\\n'\n",
      "          '    - Generate OpenAPI spec file.\\n'\n",
      "          '    - Write API documentation.\\n'\n",
      "          '\\n'\n",
      "          '6. **Testing**\\n'\n",
      "          '    - Write unit tests for each endpoint.\\n'\n",
      "          '    - Write integration tests.\\n'\n",
      "          '\\n'\n",
      "          '7. **Licensing**\\n'\n",
      "          '    - Add LICENSE file from the provided URL.\\n'\n",
      "          '    - Include the provided LICENSE text in the project.\\n'\n",
      "          '\\n'\n",
      "          '8. **Containerization**\\n'\n",
      "          '    - Write a Dockerfile for the service.\\n'\n",
      "          '    - Create a docker-compose file if necessary.',\n",
      " 'project_folder_structure': 'user-service/\\n'\n",
      "                             '├── app/\\n'\n",
      "                             '│   ├── __init__.py\\n'\n",
      "                             '│   ├── main.py\\n'\n",
      "                             '│   ├── api/\\n'\n",
      "                             '│   │   ├── __init__.py\\n'\n",
      "                             '│   │   ├── v1/\\n'\n",
      "                             '│   │   │   ├── __init__.py\\n'\n",
      "                             '│   │   │   ├── endpoints/\\n'\n",
      "                             '│   │   │   │   ├── __init__.py\\n'\n",
      "                             '│   │   │   │   ├── user.py\\n'\n",
      "                             '│   ├── core/\\n'\n",
      "                             '│   │   ├── __init__.py\\n'\n",
      "                             '│   │   ├── config.py\\n'\n",
      "                             '│   │   ├── database.py\\n'\n",
      "                             '│   ├── models/\\n'\n",
      "                             '│   │   ├── __init__.py\\n'\n",
      "                             '│   │   ├── user.py\\n'\n",
      "                             '│   ├── schemas/\\n'\n",
      "                             '│   │   ├── __init__.py\\n'\n",
      "                             '│   │   ├── user.py\\n'\n",
      "                             '│   ├── services/\\n'\n",
      "                             '│   │   ├── __init__.py\\n'\n",
      "                             '│   │   ├── user_service.py\\n'\n",
      "                             '│   ├── tests/\\n'\n",
      "                             '│   │   ├── __init__.py\\n'\n",
      "                             '│   │   ├── test_user.py\\n'\n",
      "                             '├── .gitignore\\n'\n",
      "                             '├── .dockerignore\\n'\n",
      "                             '├── Dockerfile\\n'\n",
      "                             '├── requirements.txt\\n'\n",
      "                             '├── openapi.yaml\\n'\n",
      "                             '├── LICENSE',\n",
      " 'next_task': 'The next task is to set up the initial project structure and '\n",
      "              'configure the FastAPI framework.'}\n"
     ]
    }
   ],
   "source": [
    "pp.pp(solution['parsed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that Architect Chain is ready we can start creating the Coder chain that can be used by the coder agent to complete the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we define a coder model so that we can access ti during our agent node execution.\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import ClassVar\n",
    "\n",
    "class CoderModel(BaseModel):\n",
    "    \"\"\"Coder agent output\"\"\"\n",
    "\n",
    "    steps_to_complete: str = Field(description=\"If the task cannot be completed in one step and needs external tool\")\n",
    "    files_to_create: str = Field(description=\"What all files needs to be created\")\n",
    "    file_path: str = Field(description=\"Depending on the project structure where should the code be written to\")\n",
    "    code: str = Field(description=\"Fully complete, well documented code, with all the naming standards followed that is needed to complete the task.\")\n",
    "    license_text: str = Field(description=\"A Licensing text from the user input that needs to be prefixed to each code.\")\n",
    "    task_completion: str = Field(description=\"If the assigned task is completed or not\")\n",
    "    call_next: str = Field(description=\"What to do next\")\n",
    "    \n",
    "    # deliverables: Dict[str, str] = Field(default_factory=dict, description=\"A seperate Dictionary of Tasks and their corresponding details for completion\")\n",
    "    description: ClassVar[str] = \"Schema of task completion output from Coder.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "coder_tools = [\"write_generated_code_to_file\",\"create_git_repo\",\"execute_command,download_license_file\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We May need to create args Schema for each of the other tool as well, if we want to attach all of them to the coder llm.\n",
    "Let us first create for the three below, we can create for others later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class WriteGeneratedCodeToFileSchema(BaseModel):\n",
    "    generated_code: str = Field(..., description=\"The code generated by the agent.\")\n",
    "    file_path: str = Field(..., description=\"Absolute path where the generated code should be written.\")\n",
    "\n",
    "class CreateGitRepoSchema(BaseModel):\n",
    "    project_name: str = Field(..., description=\"Name of the new Git repository that should be created.\")\n",
    "    repo_path: str = Field(..., description=\"Path where the new Git repository will be created.\")\n",
    "\n",
    "class ExecuteCommandSchema(BaseModel):\n",
    "    command: str = Field(..., description=\"The complete set of commands to be executed on the local machine in order.\")\n",
    "    repo_path: str = Field(..., description=\"Path where the repository is created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the tools dict() that can be binded with the coder llm using with_structured_output() `This approach did not work`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for StructuredTool\nargs_schema\n  subclass of BaseModel expected (type=type_error.subclass; expected_class=BaseModel)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StructuredTool\n\u001b[0;32m      3\u001b[0m tools_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite_generated_code_to_file\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mStructuredTool\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwrite_generated_code_to_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWrites the provided generated code to the specified file.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWriteGeneratedCodeToFileSchema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_generated_code_to_file\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_git_repo\u001b[39m\u001b[38;5;124m\"\u001b[39m: StructuredTool(\n\u001b[0;32m     11\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_git_repo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreates a new Git repository at the specified path.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m         args_schema\u001b[38;5;241m=\u001b[39mCreateGitRepoSchema,\n\u001b[0;32m     14\u001b[0m         func\u001b[38;5;241m=\u001b[39mcreate_git_repo\n\u001b[0;32m     15\u001b[0m     ),\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecute_command\u001b[39m\u001b[38;5;124m\"\u001b[39m: StructuredTool(\n\u001b[0;32m     17\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecute_command\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecutes a command on the local machine.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m         args_schema\u001b[38;5;241m=\u001b[39mExecuteCommandSchema,\n\u001b[0;32m     20\u001b[0m         func\u001b[38;5;241m=\u001b[39mexecute_command\n\u001b[0;32m     21\u001b[0m     ),\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoder_model\u001b[39m\u001b[38;5;124m\"\u001b[39m: StructuredTool(\n\u001b[0;32m     23\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoder_model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoder agent output\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m         args_schema\u001b[38;5;241m=\u001b[39mCoderModel,  \u001b[38;5;66;03m# Directly using the Pydantic model\u001b[39;00m\n\u001b[0;32m     26\u001b[0m         func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# No function associated; it's just a schema\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     )\n\u001b[0;32m     28\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\vkumar\\OneDrive - Imagevision.ai India Pvt Ltd\\Documents\\Projects\\Compage-Agents\\.venv\\Lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for StructuredTool\nargs_schema\n  subclass of BaseModel expected (type=type_error.subclass; expected_class=BaseModel)"
     ]
    }
   ],
   "source": [
    "from langchain.tools import StructuredTool\n",
    "\n",
    "tools_dict = {\n",
    "    \"write_generated_code_to_file\": StructuredTool(\n",
    "        name=\"write_generated_code_to_file\",\n",
    "        description=\"Writes the provided generated code to the specified file.\",\n",
    "        args_schema=WriteGeneratedCodeToFileSchema,\n",
    "        func=write_generated_code_to_file\n",
    "    ),\n",
    "    \"create_git_repo\": StructuredTool(\n",
    "        name=\"create_git_repo\",\n",
    "        description=\"Creates a new Git repository at the specified path.\",\n",
    "        args_schema=CreateGitRepoSchema,\n",
    "        func=create_git_repo\n",
    "    ),\n",
    "    \"execute_command\": StructuredTool(\n",
    "        name=\"execute_command\",\n",
    "        description=\"Executes a command on the local machine.\",\n",
    "        args_schema=ExecuteCommandSchema,\n",
    "        func=execute_command\n",
    "    ),\n",
    "    \"Coder_model\": StructuredTool(\n",
    "        name=\"Coder_model\",\n",
    "        description=\"Coder agent output\",\n",
    "        args_schema=CoderModel,  # Directly using the Pydantic model\n",
    "        func=None  # No function associated; it's just a schema\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next task is to set up the initial project structure and configure the FastAPI framework.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "import json\n",
    "Coder_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "    \n",
    "            \"\"\"<instructions>\n",
    "            You are an expert programmer collaborating with the Architect in your team to complete an end to end Coding Project.\n",
    "            You are good at writing well documented, optimized, secure and productionizable code.\n",
    "            Here are the standards that you need to follow explicitly for this project:\n",
    "            1. You do not assume anything and asks Architect for additional context and clarification if requirements are not clear.\n",
    "            2. Must follow Project Folder Structure decided by Architect.\n",
    "            3. Must Write the files to the local filesystem.\n",
    "            4. Follow microservices development standards like 12-factor application standards, domain-driven microservice architecture and clean-code development architecture standards.\n",
    "\n",
    "            Structure your answer: \n",
    "            1) Multiple steps may be needed to complete this task that needs access to some external tools {coder_tools}, if so add these steps and mark the task_completion as InComplete and call_next to call_tool.\n",
    "            2) Depending on the project structure where should the code be written to, \n",
    "            3) Fully complete, well documented code, with all the naming standards to follow, that is needed to complete the task., \n",
    "            4) A Licensing text from the user input that needs to be prefixed to each code. \n",
    "            5) Mark the assigned task as COMPLETED and set the call_next to 'Architect', only after receiving the confirmation from one of the external tools. \n",
    "            6) Mark the assigned task as INCOMPLETE and set the call_next to 'call_tool'\\n\n",
    "            Invoke the Coder_model tool to structure the output correctly. </instructions> \\n Here is the Architect task:\"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"coder_tools\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# First lets read in the input that defines the task to be performed by the multi agent setup\n",
    "architect_input = solution['parsed']['next_task']\n",
    "print(architect_input)\n",
    "Coder_llm = code_llm.with_structured_output(CoderModel, include_raw=True)\n",
    "\n",
    "coder_chain = Coder_prompt | Coder_llm\n",
    "question = f\"Here is a task for you to complete {architect_input}. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "coder_response = coder_chain.invoke({\"context\":solution[\"parsed\"]['project_folder_structure'], \"coder_tools\":coder_tools, \"messages\":[(\"user\",question)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'raw': AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_ATHNhHDCCzZ2NbhuE7LhRrAe', 'function': {'arguments': '{\"steps_to_complete\":\"1. Download the license file to include in all project files. 2. Create a Git repository for version control. 3. Write the initial FastAPI setup code to the specified file path. 4. Execute necessary commands to set up the environment.\",\"files_to_create\":\"main.py\",\"file_path\":\"src/\",\"code\":\"from fastapi import FastAPI\\\\n\\\\napp = FastAPI()\\\\n\\\\n@app.get(\\\\\"/\\\\\")\\\\ndef read_root():\\\\n    return {\\\\\"Hello\\\\\": \\\\\"World\\\\\"}\",\"license_text\":\"# Insert your license text here\\\\n\",\"task_completion\":\"INCOMPLETE\",\"call_next\":\"call_tool\"}', 'name': 'CoderModel'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'stop'}, id='run-c12058b4-b944-41d8-a97c-2c6306bbc689-0', tool_calls=[{'name': 'CoderModel', 'args': {'steps_to_complete': '1. Download the license file to include in all project files. 2. Create a Git repository for version control. 3. Write the initial FastAPI setup code to the specified file path. 4. Execute necessary commands to set up the environment.', 'files_to_create': 'main.py', 'file_path': 'src/', 'code': 'from fastapi import FastAPI\\n\\napp = FastAPI()\\n\\n@app.get(\"/\")\\ndef read_root():\\n    return {\"Hello\": \"World\"}', 'license_text': '# Insert your license text here\\n', 'task_completion': 'INCOMPLETE', 'call_next': 'call_tool'}, 'id': 'call_ATHNhHDCCzZ2NbhuE7LhRrAe'}]),\n",
      " 'parsed': {'steps_to_complete': '1. Download the license file to include in '\n",
      "                                 'all project files. 2. Create a Git '\n",
      "                                 'repository for version control. 3. Write the '\n",
      "                                 'initial FastAPI setup code to the specified '\n",
      "                                 'file path. 4. Execute necessary commands to '\n",
      "                                 'set up the environment.',\n",
      "            'files_to_create': 'main.py',\n",
      "            'file_path': 'src/',\n",
      "            'code': 'from fastapi import FastAPI\\n'\n",
      "                    '\\n'\n",
      "                    'app = FastAPI()\\n'\n",
      "                    '\\n'\n",
      "                    '@app.get(\"/\")\\n'\n",
      "                    'def read_root():\\n'\n",
      "                    '    return {\"Hello\": \"World\"}',\n",
      "            'license_text': '# Insert your license text here\\n',\n",
      "            'task_completion': 'INCOMPLETE',\n",
      "            'call_next': 'call_tool'},\n",
      " 'parsing_error': None}\n"
     ]
    }
   ],
   "source": [
    "pp.pp(coder_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Define a New State that will maintain all the statespace needed to run the architect coder flow smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "from typing_extensions import TypedDict, List\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        messages : With user question, error messages, reasoning\n",
    "        generation : Code solution\n",
    "        iterations : Number of tries\n",
    "    \"\"\"\n",
    "\n",
    "    error: str\n",
    "    messages: List\n",
    "    generation: str\n",
    "    iterations: int\n",
    "    project_name: Annotated[str, \"Project name that the user has assigned to work on\"]\n",
    "    requirements_overview: Annotated[str, \"Well built requirements document from the user input\"]\n",
    "    tasks: Annotated[str, \"Spilt the detailed requirements into independent task with as much context as possible that are crucial to follow during completion\"]\n",
    "    project_folder_structure: Annotated[str, \"Project folder structure to follow.\"]\n",
    "    next_task: Annotated[str, \"Next Task to do with all the functional and non functional details related to that task\"]\n",
    "    file_path: Annotated[str, \"Depending on the project structure where should the code be written to\", operator.add]\n",
    "    code: Annotated[str, \"Fully complete, well documented code, with all the naming standards followed that is needed to complete the task.\", operator.add]\n",
    "    license_text: Annotated[str, \"A Licensing text from the user input that needs to be prefixed to each code.\"]\n",
    "    task_completion: Annotated[str, \"If the assigned task is completed or not\"]\n",
    "    call_next: Annotated[str, \"Whom to call next\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langgraph.prebuilt import ToolExecutor, ToolInvocation, ToolNode\n",
    "\n",
    "def Architect(state: GraphState):\n",
    "    print(\"----Architect Started to Work on the Project----\")\n",
    "    \n",
    "    # Let's Grab important information from the state\n",
    "    messages = state['messages']\n",
    "    error = state['error']\n",
    "    iteration = state['iterations']\n",
    "\n",
    "    # We have been routed back to generation with an error\n",
    "    if error == \"yes\":\n",
    "        messages += [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Now, try again. Invoke the Requirements_Doc tool to structure the output with a project_name, well_documented, tasks, project_folder_structure and next_task\",\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    architect_solution = architect_chain.invoke({'messages':messages})\n",
    "\n",
    "    # Check if any fields in the schema are missing values.\n",
    "    missing_keys = []\n",
    "    for key in RequirementsDoc.__annotations__:\n",
    "        if key != 'description' and key not in architect_solution['parsed']:\n",
    "            missing_keys.append(key)\n",
    "    \n",
    "    if architect_solution['parsing_error']:\n",
    "        raw_output = architect_solution['raw']\n",
    "        error = architect_solution['parsing_error']\n",
    "        messages += [\n",
    "            (\n",
    "                \"user\",\n",
    "                f\"Error parsing your output! Be sure to invoke the tool. Output: {raw_output}. \\n Parse error: {error}\"\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    elif missing_keys:\n",
    "        messages += [\n",
    "            (\n",
    "                \"user\",\n",
    "                f\"Now, try again. Invoke the Requirements_Doc tool to structure the output with a project_name, well_documented, tasks, project_folder_structure and next_task, you missed {missing_keys} in your previous response\",\n",
    "            )\n",
    "        ]\n",
    "    else:\n",
    "        state['next_task'] = messages['parsed']['next_task']\n",
    "        state['project_name'] = messages['parsed']['project_name']\n",
    "        state['requirements_overview'] = messages['parsed']['well_documented']\n",
    "        state['tasks'] = messages['parsed']['tasks']\n",
    "        state['project_folder_structure'] = messages['parsed']['project_folder_structure']\n",
    "        \n",
    "        messages += [\n",
    "        (\n",
    "            \"assistant\",\n",
    "            \"Well document requirements is present now. see what task needs to be completed and do that now.\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # We can keep track of this so that architect agent does not get stuck in a loop\n",
    "    iteration += 1\n",
    "    return {'messages': messages, **state}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langgraph.prebuilt import ToolExecutor, ToolInvocation, ToolNode\n",
    "\n",
    "def Coder(state: GraphState):\n",
    "    print(\"----Coder Started to Work on the Task assigned----\")\n",
    "    # TODO: Implement a termination criteria, if you read through the prompt I was planning to make use of the 'task_completion' and 'call_next' fields\n",
    "    # TODO: Invoke the coder_chain with values similar to the usage in one of the above sample cells. This will explicitly define steps that needs to be done. You may need you own utility function to parse through the responses to `response['parsed'][key] for key in keys`\n",
    "    # TODO: Create a new chain to which you can bind the tools that can be called and that way you may not need a router and just loop between that llm_with_tool_chain and the coder_chain. \\\n",
    "    #       Otherwise you will need to create three different nodes that can call one of the tool_function\\\n",
    "    #       and use a router to call one of those tool node by passing the state. \n",
    "    # TODO: Create a langgraph, compile it and run it to test the flow.\n",
    "    # Note: Keep in you can always add more values to the state if needed and update the state values by returning a dictionary consisting of keys same as in Graphstate. \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you want to add MISMO Documents from the URL, you can use something like this for now, Remember this approach is very expensive and will consume thousands of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as Soup\n",
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "\n",
    "# MISMO docs\n",
    "url = \"LINK TO MISMO DOCS URL\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=20, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# Sort the list based on the URLs and get the text\n",
    "d_sorted = sorted(docs, key=lambda x: x.metadata[\"source\"])\n",
    "d_reversed = list(reversed(d_sorted))\n",
    "concatenated_content = \"\\n\\n\\n --- \\n\\n\\n\".join(\n",
    "    [doc.page_content for doc in d_reversed]\n",
    ")\n",
    "\n",
    "\n",
    "# You then pass `concatenated_content` as context to architect chain later on by doing something like this\n",
    "# solution = architect_chain.invoke({\"context\": concatenated_content, \"messages\":[(\"user\",question)]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
